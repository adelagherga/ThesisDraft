%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Towards Efficient Resolution of Thue-Mahler Equations}
\label{ch:EfficientTMSolver}

Let $a$ denote a nonzero integer and let $S=\{p_1,\dotsc,p_v\}$ be a set of rational primes. In this section, we specialize the results of \autoref{ch:AlgorithmsForTM} to the degree $3$ Thue--Mahler equation
\begin{equation} \label{Eq:TM1}
F(X,Y) = c_0 X^3 + c_1 X^{2}Y + c_2XY^2 + c_3Y^3 = a p_1^{Z_1}\cdots p_v^{Z_v},
\end{equation}
where $(X,Y) \in \mathbb{Z}^2$, $\gcd(X,Y)=1$, and $Z_i \geq 0$ for $i = 1, \dots, v$. In particular, to enumerate the set of solutions $\{X,Y, Z_1, \dots, Z_v\}$ to this equation, we follow \autoref{sec:FactorizationTM} to reduce the problem of solving \eqref{Eq:TM1} to solving finitely many so-called ``$S$-unit'' equations
\begin{equation} \label{eq:EfficientSunit}
\lambda = \delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i} - 1 = \delta_2 \prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i},
\end{equation}
where
\[\delta_1 = \frac{\theta^{(i_0)} - \theta^{(j)}}{\theta^{(i_0)} - \theta^{(k)}}\cdot\frac{\alpha^{(k)}\zeta^{(k)}}{\alpha^{(j)}\zeta^{(j)}}, \quad \delta_2 = \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\alpha^{(i_0)}\zeta^{(i_0)}}{\alpha^{(j)}\zeta^{(j)}}\]
are constants. Here, we adopt the notation of \autoref{ch:AlgorithmsForTM} and recall that we reduce \eqref{Eq:TM1} to a homogenous equation of the form
\begin{equation} \label{eq:Efficientpoly}
f(x,y) = x^3 + C_1x^2y + C_2xy^2 + C_3y^3 = cp_1^{z_1}\cdots p_v^{z_v},
\end{equation}
where $\gcd(x,y) = 1$ and $\gcd(c,p_i) = 1$ for $i = 1, \dots, p_v$. Moreover, we set
\begin{equation} \label{eq:Efficientg}
g(t) = f(t,1) = t^3 + C_1t^2 + C_2t + C_3
\end{equation}
so that $K = \mathbb{Q}(\theta)$ with $g(\theta) = 0$. Recall that $\zeta$ in \eqref{eq:EfficientSunit} denotes a root of unity in $K$, while $\{\eps_1, \dots, \eps_r\}$ is a set of fundamental units of $\mathcal{O}_K$. In this case, as $K$ is a degree $3$ extension of $\mathbb{Q}$, we either have $3$ real embeddings of $K$ into $\mathbb{C}$, or one real embedding of $K$ into $\mathbb{C}$ and a pair of complex conjugate embeddings of $K$ into $\mathbb{C}$. Thus either $r = 1$ or $r = 2$. 

In this section, we describe new techniques to solve equation~\eqref{eq:EfficientSunit} via a global Weil height. This work is part of the on-going collaborative project \cite{GhKaMaSi}. Notably, the ideas presented in this chapter do not yet yield a full degree $3$ Thue-Mahler solver. Indeed, for the time being, only those Thue-Mahler equations with $r = 2$ are considered. However, when $r = 1$, the general setup established in this chapter remains the same. 

%---------------------------------------------------------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------------------------------------------------------%
\section{Decomposition of the Weil height} 
\label{sec:DecompositionofWeilHeight}

The sieves of \cite{TW3} involve logarithms which are of local nature. To obtain a global sieve, we work instead with the global logarithmic Weil height. This height is invariant under conjugation and admits a decomposition into local heights which can be related to complex and $p$-adic logarithms. 

Let $n_1, \dots, n_{\nu}, a_1, \dots, a_r$ be a solution to \eqref{eq:EfficientSunit} and consider the Weil height of
\[\frac{\delta_2}{\lambda}= \prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(j)}}{\varepsilon_i^{(i_0)}}\right)^{a_i} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{n_i}.\]
Given the global Weil height of $\delta_2/\lambda$, or all the local heights of $\delta_2/\lambda$, we will construct several ellipsoids `containing' $n_1, \dots, n_{\nu}, a_1, \dots, a_r$ such that the volume of the ellipsoids are as small as possible. We begin by computing the height of $\delta_2/\lambda$. 

Let $L$ be the splitting field of $K$. Recall that for cubic extensions $K$, the Galois group $\Gal(L/\mathbb{Q})$ is isomorphic to either the alternating group $A_3$ or the symmetric group $S_3$. 

\begin{lemma}\label{lem:cancellation}
Let $\mathfrak{p}$ be a prime ideal of $\mathcal{O}_K$ and let $\mathfrak{P}$ denote an ideal of $\mathcal{O}_L$ lying above it. Suppose $\sigma_{i_0}: L \to L$, $\theta \mapsto \theta^{(i_0)}$ and $\sigma_{j}: L \to L$, $\theta \mapsto \theta^{(j)}$ are two automorphisms of $L$ such that $(i_0,j,k)$ forms a subgroup of $\Gal(L/\mathbb{Q})$ of order $3$. Let $\mathfrak{P}^{(i_0)} = \sigma_{i_0}(\mathfrak{P})$ and $\mathfrak{P}^{(j)} = \sigma_{j}(\mathfrak{P})$ be the prime ideals lying over $\mathfrak{p}^{(i_0)}$, $\mathfrak{p}^{(j)}$ respectively. For $i = 1, \dots, \nu$, 
\[\left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)\mathcal{O}_L 
	 = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_1^{(j)})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_1)}}\right)^{a_{1i}} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}^{(j)}_{\nu})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_{\nu})}}\right)^{a_{\nu i}}\]
where $\mathfrak{P}^{(j)} \neq \mathfrak{P}^{(i_0)}$ for all $\mathfrak{P}$ lying above $\mathfrak{p}$ in $K$. 
\end{lemma}

\begin{proof}
Since 
\[(\gamma_i)\mathcal{O}_K = \mathfrak{p}_1^{a_{1i}} \cdots \mathfrak{p}_{\nu}^{a_{\nu i}},\]
for $i = 1, \dots, \nu$, where
\[\mathfrak{p}_i\mathcal{O}_L=\prod_{\mathfrak{P}\mid\mathfrak{p}_i} \mathfrak{P}^{e(\mathfrak{P}\mid\mathfrak{p}_i)},\]
it holds that
\[(\gamma_i)\mathcal{O}_L = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \mathfrak{P}^{e(\mathfrak{P}\mid\mathfrak{p}_1)}\right)^{a_{1i}} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \mathfrak{P}^{e(\mathfrak{P}\mid\mathfrak{p}_{\nu})}\right)^{a_{\nu i}}.\]

Let $\mathfrak{P}^{(i_0)},\mathfrak{P}^{(j)}$ denote the ideal $\mathfrak{P}$ under the automorphisms of $L$
\[\sigma_{i_0}: L \to L, \quad \theta \mapsto \theta^{(i_0)} \quad \text{ and } \quad \sigma_{j}: L \to L, \quad \theta \mapsto \theta^{(j)},\]
respectively. That is, $\mathfrak{P}^{(i_0)} = \sigma_{i_0}(\mathfrak{P})$ and $\mathfrak{P}^{(j)} = \sigma_{j}(\mathfrak{P})$. Then
\[\left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)\mathcal{O}_L 
	 = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_1^{(j)})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_1)}}\right)^{a_{1i}} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}^{(j)}_{\nu})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_{\nu})}}\right)^{a_{\nu i}}.\]

To show that $\mathfrak{P}^{(j)} \neq \mathfrak{P}^{(i_0)}$ for all $\mathfrak{P}$ lying above $\mathfrak{p}$ in $K$, we consider the decomposition group of $\mathfrak{P}$, 
\[D(\mathfrak{P}|p) = \{\sigma \in G \ : \ \sigma(\mathfrak{P}) = \mathfrak{P}\}.\]
Iterating through all possible decompositions of $\mathfrak{p}$ in $L$, we observe that $\mathfrak{P}^{(i_0)} \neq \mathfrak{P}^{(j)}$ whenever $D(\mathfrak{P}_i|p)$ does not have cardinality $2$. Since $(i_0,j,k)$ forms an order $3$ subgroup of $\Gal(L/\mathbb{Q})$, it cannot coincide with $D(\mathfrak{P}|p)$ and therefore cannot lead to $\mathfrak{P}^{(i_0)} = \mathfrak{P}^{(j)}$. 
\end{proof}

For the remainder of this paper, we assume that $(i_0,j,k)$ are automorphisms of $L$ selected as in Lemma~\ref{lem:cancellation}.

\begin{lemma}\label{lem:ordpz}
Let $\mathfrak{p}$ be a prime ideal of $\mathcal{O}_K$ and let $\mathfrak{P}$ denote an ideal of $\mathcal{O}_L$ lying above it. Let $\mathfrak{P}^{(i_0)} = \sigma_{i_0}(\mathfrak{P})$ and $\mathfrak{P}^{(j)} = \sigma_{j}(\mathfrak{P})$ be the prime ideals lying over $\mathfrak{p}^{(i_0)}$, $\mathfrak{p}^{(j)}$ respectively. We have
\[\ord_{\mathfrak{P}}\left(\frac{\delta_2}{\lambda}\right)=
\begin{cases}
(u_l - r_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})	
	& \textnormal{ if } \mathfrak{P}^{(j)} \mid p_l , \ p_l \in \{p_1,\dots, p_{\nu}\}\\
(r_l - u_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})
	& \textnormal{ if } \mathfrak{P}^{(i_0)}\mid p_l, \ p_l \in \{p_1,\dots, p_{\nu}\}\\
0 	& \textnormal{ otherwise}.
\end{cases}\]
\end{lemma}
\begin{proof}

By Lemma~\ref{lem:cancellation}, we have 
\begin{align*}
\left(\frac{\delta_2}{\lambda}\right)\mathcal{O}_L
	& = \left( \frac{\gamma_1^{(j)}}{\gamma_1^{(i_0)}}\right)^{n_1}\cdots \left( \frac{\gamma_{\nu}^{(j)}}{\gamma_{\nu}^{(i_0)}}\right)^{n_{\nu}} \mathcal{O}_L\\
	& = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_1^{(j)})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_1)}}\right)^{u_1 - r_1} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}^{(j)}_{\nu})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_{\nu})}}\right)^{u_{\nu} - r_{\nu}}.
\end{align*}
It follows that 
\[\ord_{\mathfrak{P}}\left( \frac{\delta_2}{\lambda}\right)=
\begin{cases}
(u_l - r_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})	
	& \textnormal{ if } \mathfrak{P}^{(j)} \mid p_l , \ p_l \in \{p_1,\dots, p_{\nu}\}\\
(r_l - u_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})
	& \textnormal{ if } \mathfrak{P}^{(i_0)}\mid p_l, \ p_l \in \{p_1,\dots, p_{\nu}\}\\
0 	& \textnormal{ otherwise}.
\end{cases}\]
\end{proof}

Let $\log^+(\cdot)$ denote the real valued function $\max(\log(\cdot), 0)$ on $\mathbb{R}_{\geq 0}$. 

\begin{proposition}\label{prop:heightdecomp}
The height $h\left(\frac{\delta_2}{\lambda}\right)$ admits a decomposition 
\begin{equation} \label{eq:hdecomp}
h\left(\frac{\delta_2}{\lambda}\right) = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| + \frac{1}{[L:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}.
\end{equation}
In particular, when $\deg(g(t)) = 3$, 
\[\sum_{w :L \to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} = 
b\max_{w:L\to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}\]
where
\[b =
\begin{cases}
2 & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
1 & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3.
\end{cases}\]
\end{proposition}
For ease of notation, let $S^* = S \cup \{v : L \to \mathbb{C}\}$ and write 
\[h\left(\frac{\delta_2}{\lambda}\right) = \frac{1}{[K:\mathbb{Q}]}\sum_{v \in S^*}h_{v}\left(\frac{\delta_2}{\lambda}\right).\]
By Proposition~\ref{prop:heightdecomp}, when $v = p_l$ is a finite place, 
\[h_{v}\left(\frac{\delta_2}{\lambda}\right) = \log(p_l)|u_l - r_l|,\]
whereas we write
\[h_{v}\left(\frac{\delta_2}{\lambda}\right) = \frac{1}{[L:K]} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}\]
for all infinite places $v = w$. Finally, let $m$ denote the number of embeddings of $L$ into $\mathbb{C}$,  $m = \# \{v : L \to \mathbb{C}\}$. 

\begin{proof}[Proof of Proposition~\ref{prop:heightdecomp}]Since $\frac{\delta_2}{\lambda} \in L$, the definition of the absolute logarithmic Weil height gives
\[h\left(\frac{\delta_2}{\lambda}\right)=\frac{1}{[L:\mathbb{Q}]}\sum_{w \in M_L} \log \max \left\{ \left\|\frac{\delta_2}{\lambda}\right\|_{w}, 1\right\}\]
where $||z||_w$ is the usual norms and $M_L$ is a set of inequivalent absolute values on $L$. In particular, if $w: L \to \mathbb{C}$ is an infinite place, we obtain
\[ \log \max \left\{ \left\|\frac{\delta_2}{\lambda}\right\|_{w}, 1\right\} = \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}.\]
Writing $z = \frac{\delta_2}{\lambda}$ and $w = \mathfrak{P}$ a finite place, we have
\[ \log \max \{ \|z\|_{w}, 1\} = \max \left\{ \log\left(\frac{1}{N(\mathfrak{P})^{\ord_{\mathfrak{P}}(z)}} \right), 0\right\}. \]
By Lemma~\ref{lem:ordpz}, 
\[\ord_{\mathfrak{P}}\left( \frac{\delta_2}{\lambda}\right)=
\begin{cases}
(u_l - r_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})	
	& \textnormal{ if } \mathfrak{P}^{(j)} \mid p_l , \ p_l \in \{p_1,\dots, p_{\nu}\}\\
(r_l - u_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})
	& \textnormal{ if } \mathfrak{P}^{(i_0)}\mid p_l, \ p_l \in \{p_1,\dots, p_{\nu}\}\\
0 	& \textnormal{ otherwise}.
\end{cases}\]
That is, for $\mathfrak{P}^{(j)}\mid p_l$ where $p_l \in \{p_1, \dots, p_{\nu}\}$, we have
\begin{align*}
 \log \max \{ ||z||_{w}, 1\}	
 	& = \max \left\{ \log\left(\frac{1}{N(\mathfrak{P})^{\ord_{\mathfrak{P}}(z)}} \right), 0\right\}\\
	& = \max \left\{ \log\left(\frac{1}{N(\mathfrak{P})^{(u_l - r_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})}} \right), 0\right\}\\
	& = \max \left\{ -(u_l - r_l)f(\mathfrak{P}^{(j)}\mid p_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})\log(p_l), 0\right\}.
\end{align*}
Moreover, for $p_l \in \{p_1, \dots, p_{\nu}\}$, there is one unique prime ideal $\mathfrak{p}_l$ in the ideal equation \eqref{eq:TMfactored} lying above $p_l$ in $K$. Hence, each $\mathfrak{P}$ lying over $p_l$ must also lie over $\mathfrak{p}_l$. Now, 
\begin{align*}
& \sum_{\mathfrak{P}^{(j)} \mid \mathfrak{p}_l^{(j)}} \log \max \left\{ \left\|\frac{\delta_2}{\lambda}\right\|_{w}, 1\right\} \\
	& \quad = \sum_{\mathfrak{P}^{(j)} \mid \mathfrak{p}_l^{(j)}} \max \left\{ -(u_l - r_l)f(\mathfrak{P}^{(j)}\mid p_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})\log(p_l), 0\right\}\\
	& \quad = \max \left\{ (r_l - u_l)\log(p_l), 0\right\}f(\mathfrak{p}_l^{(j)}\mid p_l)[L:\mathbb{Q}(\theta^{(j)})]\\
	& \quad = \max \left\{ (r_l - u_l)\log(p_l), 0\right\}f(\mathfrak{p}_l^{(j)}\mid p_l)[L:K],
\end{align*}
where the last inequality follows from $K = \mathbb{Q}(\theta) \cong \mathbb{Q}(\theta^{(j)})$.

Similarly, for $\mathfrak{P}^{(i_0)}\mid p_l$ where $p_l \in \{p_1, \dots, p_{\nu}\}$, we have
\begin{align*}
 \log \max \{ \|z\|_{w}, 1\}	
 	& = \max \left\{ \log\left(\frac{1}{N(\mathfrak{P})^{\ord_{\mathfrak{P}}(z)}} \right), 0\right\}\\
	& = \max \left\{ \log\left(\frac{1}{N(\mathfrak{P})^{(r_l - u_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})}} \right), 0\right\}\\
	& = \max \left\{ -(r_l - u_l)f(\mathfrak{P}^{(i_0)}\mid p_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})\log(p_l), 0\right\},
\end{align*}
and so
\begin{align*}
\sum_{\mathfrak{P}^{(i_0)} \mid \mathfrak{p}_l^{(i_0)}} \log \max \left\{ \left\|\frac{\delta_2}{\lambda}\right\|_{w}, 1\right\}
	& = \max \left\{ (u_l - r_l)\log(p_l), 0\right\}f(\mathfrak{p}_l^{(i_0)}\mid p_l)[L:K].
\end{align*}

Lastly, if $w = \mathfrak{P}$ such that $\mathfrak{P} \neq \mathfrak{P}^{(i_0)},  \mathfrak{P}^{(j)}$, we have
\[\log \max \{ \|z\|_{w}, 1\} = \max \left\{ \log\left(\frac{1}{N(\mathfrak{P})^{\ord_{\mathfrak{P}}(z)}} \right), 0\right\}=0.\]
Putting this all together yields the first result \eqref{eq:hdecomp}. 

To prove the second statement, let $z = d^{(j)}/d^{(i_0)} \in L$. The orbit of $z$ is
\[\begin{cases}
\left\{\frac{d^{(j)}}{d^{(i_0)}}, \frac{d^{(k)}}{d^{(j)}}, \frac{d^{(i_0)}}{d^{(k)}}, \frac{d^{(j)}}{d^{(k)}}, \frac{d^{(k)}}{d^{(i_0)}}, \frac{d^{(i_0)}}{d^{(j)}} \right\} & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
\left\{\frac{d^{(j)}}{d^{(i_0)}}, \frac{d^{(k)}}{d^{(j)}}, \frac{d^{(i_0)}}{d^{(k)}}\right\} & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3.
\end{cases}\]
Choose $a,b,c\in\{i_0,j,k\}$ such that 
\[|d^{(a)}| \geq |d^{(b)}| \geq |d^{(c)}|.\]
Now, if $\Gal(L/\mathbb{Q}) \cong S_3$, we obtain
\begin{align*}
& \sum_{w :L \to \mathbb{C}} \log \max \{ |w(z)|, 1\} \\
	& = \log \max \left\{ \left|\frac{d^{(a)}}{d^{(b)}}\right|, 1\right\} + \log \max \left\{ \left|\frac{d^{(b)}}{d^{(c)}}\right|, 1\right\} + \log \max \left\{ \left|\frac{d^{(c)}}{d^{(a)}}\right|, 1\right\} \\
	& \quad +  \log \max \left\{ \left|\frac{d^{(a)}}{d^{(c)}}\right|, 1\right\} + \log \max \left\{ \left|\frac{d^{(a)}}{d^{(c)}}\right|, 1\right\} + \log \max \left\{ \left|\frac{d^{(c)}}{d^{(b)}}\right|, 1\right\}\\
	& = \log \left|\frac{d^{(a)}}{d^{(b)}}\right| + \log \left|\frac{d^{(b)}}{d^{(c)}}\right| + \log \left|\frac{d^{(a)}}{d^{(c)}}\right| \\
	& = 2\log \left|\frac{d^{(a)}}{d^{(c)}}\right|.
\end{align*}
Alternatively, if $\Gal(L/\mathbb{Q}) \cong A_3$, it follows that
\begin{align*}
& \sum_{w :L \to \mathbb{C}} \log \max \{ |w(z)|, 1\} \\
	& = \log \max \left\{ \left|\frac{d^{(a)}}{d^{(b)}}\right|, 1\right\} + \log \max \left\{ \left|\frac{d^{(b)}}{d^{(c)}}\right|, 1\right\} + \log \max \left\{ \left|\frac{d^{(c)}}{d^{(a)}}\right|, 1\right\} \\
	& = \log \left|\frac{d^{(a)}}{d^{(b)}}\right| + \log \left|\frac{d^{(b)}}{d^{(c)}}\right| \\
	& = \log \left|\frac{d^{(a)}}{d^{(c)}}\right|.
\end{align*}
The proposition now follows by setting $z = \frac{\delta_2}{\lambda}$. 
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------------------------%
\section{Initial height bounds}
\label{sec:InitialHeightBounds}

We seek solutions to equaition~\eqref{eq:EfficientSunit}. We recall this equation presently, 
\begin{equation*}
\lambda = \delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i} - 1 = \delta_2 \prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}.
\end{equation*}
To simplify notation, we write
\[\tilde{y} =  \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}, \quad 
\tilde{x} = \prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}\]
so that equation~\eqref{eq:EfficientSunit} becomes
\begin{equation} \label{eq:TrueSunit}
\delta_1\tilde{y} - \delta_2\tilde{x} = 1.
\end{equation}
Let $z= \frac{1}{\tilde{x}} = \frac{\delta_2}{\lambda}$ and denote by $\Sigma$ the set of pairs $(\tilde{x},\tilde{y})$ satisfying \eqref{eq:TrueSunit}. That is, $\Sigma$ denotes the set of tuples $(n_1, \dots, n_{\nu}, a_1, \dots, a_r)$ corresponding to $(\tilde{x},\tilde{y})$ which satisfy \eqref{eq:TrueSunit}.

Let $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu + m}$ with $\mathbf{0}\leq \mathbf{l}\leq \mathbf{h}$. Then we define $\Sigma(\mathbf{l},\mathbf{h})$ as the set of all $(\tilde{x},\tilde{y}) \in \Sigma$ such that $\left(h_v\left(\frac{\delta_2}{\lambda}\right)\right)\leq \mathbf{h}$ and such that $\left(h_v\left(\frac{\delta_2}{\lambda}\right)\right)\nleq \mathbf{l}$, and write $\Sigma(\mathbf{h})=\Sigma(\mathbf{l},\mathbf{h})$ if $\mathbf{l}=\mathbf{0}$. Additionally, for each place $w$, we denote by $\Sigma_w(\mathbf{l},\mathbf{h})$ the set of all $(\tilde{x},\tilde{y})\in\Sigma(\mathbf{h})$ such that $h_w(z)>l_w$. 

Recall the minimal polynomial $g(t)$ of $K$, \eqref{eq:Efficientg}, derived from 
\[f(x,y) = x^3 + C_1 x^{2}y + C_2xy^2 + C_3y^3 = cp_1^{z_1}\cdots p_v^{z_v}.\]
For $S = \{p_1, \dots, p_v\}$, let $N_S = \prod_{p\in S}p$ and set 
\[b_S	 = 1728 N_S^2 \prod_{p \notin S} p^{\min(2,\ord_p(b))}\]
for any integer $b$. In particular, we take $b = 432 \Delta c^2$ with $\Delta$ the discriminant of $f$. Denote by $h(f-c)$ the maximum logarithmic Weil heights of the coefficients of the polynomial $f - c$,
\[h(f-c) = \max(\log|C_1|, \log|C_2|, \log|C_3|, \log|c|).\]

Now, setting
\[\Omega = 2b_S \log(b_S) + 172h(f-c),\]
we obtain, by Corollary J (ii) of \cite{KanMat}, the following height bound on any solution $(x,y)$ of \eqref{eq:Efficientpoly}
\[\max(h(x),h(y))\leq \Omega.\]
To translate this result for use with our logarithmic Weil height \eqref{eq:hdecomp}, we have the following lemma. 
\begin{lemma} \label{lem:TMinitialheight}
Let ${\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}}$ be any solution of \eqref{eq:EfficientSunit} and let 
\begin{equation} \label{eq:Omegaprime}
\Omega' = [K:\mathbb{Q}](2h(\alpha) + 4\Omega + 2h(\theta) + 2\log(2)).
\end{equation}
If $\mathbf{h} \in\mathbb{R}^{\nu + m}$ with $\mathbf{h} = (\Omega')$, then $\mathbf{m}\in \Sigma(h)$.
\end{lemma}

\begin{proof}
Let $(\tilde{x},\tilde{y}) \in \Sigma$. We show that the corresponding value $z = \frac{1}{\tilde{x}} = \frac{\delta_2}{\lambda}$ arising from this choice of $\tilde{x},\tilde{y}$ satisfies
\[\mathbf{0} < \left(h_v\left(\frac{\delta_2}{\lambda}\right)\right)\leq \mathbf{h}.\]

As stated earlier, any solution $x,y$ of $f(x,y) = c p_1^{z_1}\cdots p_v^{z_v}$ satisfies
\[\max(h(x),h(y)) \leq \Omega.\]
Taking the height of 
\[\beta = x-y\theta = \alpha \zeta \varepsilon_1^{a_1} \cdots \varepsilon_r^{a_r}\cdot \gamma_1^{n_1}\cdots \gamma_{\nu}^{n_{\nu}},\]
we obtain
\[h(\beta) = h(x) + h(\theta) + h(y) + \log{2}  \leq 2\Omega + h(\theta) + \log{2}.\]
In particular, as $h(\beta) = h(\beta^{(i)})$, 
\[h(\beta^{(i)}) \leq 2\Omega + h(\theta) + \log{2}.\]
Now, 
\[\delta_2\tilde{x} 
	= \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\alpha^{(i_0)}\zeta^{(i_0)}}{\alpha^{(j)}\zeta^{(j)}} \prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}  
	= \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\beta^{(i_0)}}{\beta^{(j)}},\]
meaning that $\tilde{x}$ may be written as
\[\tilde{x} =\frac{\beta^{(i_0)}}{\beta^{(j)}}\cdot \frac{\alpha^{(j)}\zeta^{(j)}}{\alpha^{(i_0)}\zeta^{(i_0)}}.\]
Hence, 
\[h(\tilde{x})	 = 2h(\beta) + 2h(\alpha) \leq 4\Omega + 2h(\theta) + 2\log{2} + 2h(\alpha).\]
Finally, we observer that 
\[h(z) = h(1/\tilde{x}) \leq 4\Omega + 2h(\theta) + 2\log{2} + 2h(\alpha).\]
Together with $\displaystyle \frac{1}{[K:\mathbb{Q}]}h_v\left(\frac{\delta_2}{\lambda}\right) \leq h\left(\frac{\delta_2}{\lambda}\right)$, this implies
\[h_v\left(\frac{\delta_2}{\lambda}\right) \leq [K:\mathbb{Q}]\left(4\Omega + 2h(\theta) + 2\log{2} + 2h(\alpha)\right) = \Omega'.\]
Of course, by definition, we have $h_v\left(\frac{\delta_2}{\lambda}\right) \geq 0$, so that $(\tilde{x},\tilde{y}) \in \Sigma(h)$ as required. 
\end{proof}

%---------------------------------------------------------------------------------------------------------------------------------------------%
\section{Coverings of $\Sigma$}
\label{sec:CoveringsofSigma}

From \autoref{sec:InitialHeightBounds}, we now know that all solutions $(\tilde{x},\tilde{y}) \in \Sigma$ satisfy $\mathbf{m}\in \Sigma(h)$ if ${\mathbf{h} = (\Omega')}$. In the notation of \autoref{sec:InitialHeightBounds}, we have the following result. 

\begin{lemma}\label{lem:covering}
Let $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu+m}$ with $\mathbf{0}\leq \mathbf{l}\leq \mathbf{h}$. It holds that $\Sigma(\mathbf{h})=\Sigma(\mathbf{l},\mathbf{h})\cup \Sigma(\mathbf{l})$ and $\Sigma(\mathbf{l},\mathbf{h})=\cup_{v \in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$.
\end{lemma}

\begin{proof}
Suppose $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{h})$. By definition this means, $(h_v(z))\leq \mathbf{h}$ and that $h_v(z) > 0$ for at least one coordinate $v$. Since $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$, it follows that either $(h_v(z))\leq \mathbf{l}$ or $(h_v(z))\nleq \mathbf{l}$. That is, either all coordinates satisfy $h_v(z) \leq l_v$, or there is at least one coordinate for which $h_v(z) > l_v$. This means that either $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l})$ or $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l},\mathbf{h})$, and so $\Sigma(\mathbf{h}) \subseteq \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$.

Conversely, suppose  $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$. It follows that either $(h_v(z))\leq \mathbf{h} \text{ and } (h_v(z))\nleq \mathbf{l}$ or $(h_v(z))\leq \mathbf{l} \text{ and } (h_v(z))\nleq \mathbf{0}$. In either case, this means that $(h_v(z)) \leq \mathbf{h}$ and $(h_v(z)) \nleq \mathbf{0}$. Hence $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{h})$ and $\Sigma(\mathbf{h}) \supseteq \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$.

To prove the second equality, let $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l},\mathbf{h})$. Then there exists $w\in S^*$ with $h_w(z)>l_w$ so that $(\tilde{x},\tilde{y})$ lies in $\Sigma_w(\mathbf{l},\mathbf{h})$. Hence $\Sigma(\mathbf{l},\mathbf{h}) \subseteq \cup_{v\in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$. Lastly, since each set $\Sigma_v(\mathbf{l},\mathbf{h})$ is contained in $\Sigma(\mathbf{l},\mathbf{h})$ it follows that $\Sigma(\mathbf{l},\mathbf{h})=\cup_{v\in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$ as required. 
\end{proof}

Let $\mathbf{h}_0 = (\Omega', \dots, \Omega')$ denote the vector consisting of the initial bound $\Omega'$. By Proposition~\ref{lem:TMinitialheight}, every solution of \eqref{eq:EfficientSunit} is contained in $\mathbf{h}_0$. Therefore, we write $\Sigma = \Sigma(\mathbf{h}_0)$. Consider the pairs $(\mathbf{l}_n,\mathbf{h}_n)\in \mathbb{R}^{\nu + m}\times \mathbb{R}^{\nu + m}$ with $\mathbf{0}\leq \mathbf{l}_n\leq \mathbf{h}_n$ and $\mathbf{h}_{n+1}=\mathbf{l}_{n}$ for $n=0,\dotsc,N$. Then we can cover $\Sigma$: 
$$\Sigma=\Sigma(\mathbf{l}_{N})\cup\bigl(\cup_{n=0}^{N}\cup_{v\in S^*}\Sigma_v(\mathbf{l}_n,\mathbf{h}_n)\bigl).$$
Indeed this follows directly by applying Lemma~\ref{lem:covering} $N$ times. In particular, Lemma~\ref{lem:covering} gives  $$\Sigma=\Sigma(\mathbf{h}_0), \quad \Sigma(\mathbf{h})=\Sigma(\mathbf{l},\mathbf{h})\cup \Sigma(\mathbf{l}) \quad \textnormal{and} \quad \Sigma(\mathbf{l},\mathbf{h})=\cup_{v\in S^*}\Sigma_v(\mathbf{l},\mathbf{h}).$$
After choosing a good sequence of lower and upper bounds $\mathbf{l}_n,\mathbf{h}_n$ covering the whole space $\Sigma$, we are reduced to computing $\Sigma_v(\mathbf{l},\mathbf{h})$ for each $v \in S^*$. In the following section, we construct the ellipsoids associated to each $\Sigma_v(\mathbf{l},\mathbf{h})$, after which we describe the sieve allowing us to compute the solutions of each $\Sigma_v(\mathbf{l},\mathbf{h})$. 


%---------------------------------------------------------------------------------------------------------------------------------------------%

\section{Construction of the ellipsoids}
\label{sec:ConstructionofEllipsoids}

In \autoref{sec:CoveringsofSigma}, we establish that for a suitable pair of vectors $\mathbf{l}, \mathbf{h}$, solving \eqref{eq:EfficientSunit} reduces to computing $\Sigma_v(\mathbf{l},\mathbf{h})$ for each $v \in S^*$. In this section, we construct the ellipsoids associated to each $\Sigma_v(\mathbf{l},\mathbf{h})$, which will subsequently allow us to compute all solutions of $\Sigma_v(\mathbf{l},\mathbf{h})$. 

We begin with the quadratic form $q_f=A^TD^2A$ on $\mathbb{Z}^{\nu}$, where $D^2$ is a $\nu \times \nu$ diagonal matrix with diagonal entries $\lfloor\frac{\log(p_i)^2}{\log(2)^2}\rfloor$ for $p_i \in S$. Recall that $A$ is the matrix generated in either \autoref{subsec:FactorizationTMwithoutOK} or \autoref{subsec:FactorizationTMwithoutOK}. As $A$ is invertible, our choice of entries in $D$ guarantees that this quadratic form is positive definite. This will become very important later in the sieve when we will need to apply many instances of the Fincke-Pohst algorithm. 

\begin{lemma} \label{lem:boundqf}
For any solution $(x,y, n_1, \dots, n_{\nu}, a_1, \dots, a_r)$ of \eqref{eq:EfficientSunit} with $\mathbf{n} = (n_1, \dots, n_{\nu})$, we have 
\[\frac{\log(2)^2}{[K:\mathbb{Q}]}q_f(\mathbf{n}) < \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2.\] 
\end{lemma}

\begin{proof}
Recall from \autoref{subsec:FactorizationTMwithoutOK} and \autoref{subsec:FactorizationTMwithOK} that
\[A\mathbf{n} = \mathbf{u} - \mathbf{r}.\]
Assume first that $2 \notin S$ so that
\begin{align*}
q_f(\mathbf{n})	
	 = (A\mathbf{n})^{\text{T}}D^2A\mathbf{n}
	 = (\mathbf{u} - \mathbf{r})^{\text{T}}D^2(\mathbf{u} - \mathbf{r})
	 = \sum_{l = 1}^{\nu}\left\lfloor\frac{\log(p_l)^2}{\log(2)^2}\right\rfloor|u_l-r_l|^2.
\end{align*}
Multiplication by $\frac{\log(2)^2}{[K:\mathbb{Q}]}$ then gives
\begin{align*}
\frac{\log(2)^2}{[K:\mathbb{Q}]}q_f(\mathbf{n})  
	& = \frac{\log(2)^2}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \left\lfloor\frac{\log(p_l)^2}{\log(2)^2}\right\rfloor|u_l -r_l|^2 \\
 	& \leq \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2,
\end{align*}
where all terms in the summand are positive. 

If $2 \in S$, we have
\begin{align*}
q_f(\mathbf{n})	
	 = (A\mathbf{n})^{\text{T}}D^2A\mathbf{n}
	 = |u_1 - r_1|^2 + \sum_{l = 2}^{\nu}\left\lfloor\frac{\log(p_l)^2}{\log(2)^2}\right\rfloor|u_l-r_l|^2.
\end{align*}
It follows that
\begin{align*}
\frac{\log(2)^2}{[K:\mathbb{Q}]}q_f(\mathbf{n}) 
	& \leq \frac{\log(2)^2}{[K:\mathbb{Q}]}\left( |u_1 - r_1|^2 + \sum_{l = 2}^{\nu} \frac{\log(p_l)^2}{\log(2)^2}|u_l -r_l|^2\right) \\
	& = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2.
\end{align*}
\end{proof}

We now briefly re-examine the decomposition of $h\left(\frac{\delta_2}{\lambda}\right)$ into local heights, 
\[h\left(\frac{\delta_2}{\lambda}\right) = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| + \frac{1}{[L:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}.\]
In particular, for every finite place $v$, Lemma~\ref{lem:boundqf} tells us that any bound $h_v$ on $h_v\left(\frac{\delta_2}{\lambda}\right)$ yields a bound on $\frac{\log(2)^2}{[K:\mathbb{Q}]}q_f(\mathbf{n})$. In the remainder of this section, we build analogous bounds on the exponents $a_1, \dots, a_r$ of the fundamental units. 

Recall $r = 1$ or $r = 2$ for the degree $3$ Thue-Mahler equation~\eqref{eq:Efficientpoly} in question. Choose a set $I$ of embeddings $L \rightarrow \mathbb{C}$ of cardinality $r$. For $r = 1$, this is simply
\[R = \begin{pmatrix}
	\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1}\right| \end{pmatrix}.\]
Clearly, as long as we choose $\iota_1$ such that $\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1}\right| \neq 0$, this matrix is invertible.

When $r = 2$, we let $I$ be the set of embeddings $L \to \mathbb{C}$ of cardinality $2$ such that for any $\alpha \in K$, it holds that $I\alpha^{(i_0)} \cup I\alpha^{(j)} = \Gal(L/\mathbb{Q})\alpha$. Let $R$ be the $2 \times 2$ matrix
\[R = \begin{pmatrix}
	\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1}\right| &
	\log\left|\left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1}\right|\\
	\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2}\right| &
	\log\left|\left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2}\right|\\
	\end{pmatrix}.\]
\begin{lemma}
When $r = 2$, the matrix $R$ has an inverse,
\[R^{-1} = \begin{pmatrix}
	\overline{r}_{11} & \overline{r}_{12} \\
	\overline{r}_{21} & \overline{r}_{22}
\end{pmatrix}.\]
\end{lemma}
	
\begin{proof}
Suppose that $\mathbf{m}\in\mathbb{Z}^{r}$ satisfies $R\mathbf{m}=\mathbf{0}$. Then for each $\iota\in I$ it holds that 
\[\sum_{i=1}^r m_{\eps_i} \log\left|\left(\frac{\varepsilon_i^{(j)}}{\varepsilon_i^{(i_0)}}\right)^{\iota_1}\right| =0,\] and hence 
\[\prod_{i=1}^r \left|\left(\frac{\varepsilon_i^{(j)}}{\varepsilon_i^{(i_0)}}\right)^{\iota_1}\right|^{m_{\eps_i}}=1.\] This together with $I(i)\cup I(j)=Gal(L/\mathbb{Q})$ implies that all conjugates of $\alpha=\prod_{i=1}^r \eps_i^{m_{\eps_i}}$ have the same absolute value. Since all $\eps_i$ are units of $\mathcal{O}_K$, it follows that $|\alpha|^{[L:\mathbb{Q}]}=N(\alpha)=1$ and hence $\alpha$ is a root of unity in $K$. On using that  the elements $\eps_i$ are multiplicatively independent, we obtain that $\mathbf{m}=\mathbf{0}$.  Then linear algebra gives $R^{-1}\in\mathbb{R}^{r\times r}$, completing the proof. 
\end{proof}

For the remainder of this chapter, we specialize to the real case, $r = 2$. The setup for $r = 1$ follows closely the work described here, yet poses other difficulties when defining the corresponding sieves. This case is treated in the on-going results of \cite{GhKaMaSi}. 

Now, for any solution $(x,y, n_1, \dots, n_{\nu}, a_1, a_2)$ of \eqref{eq:EfficientSunit}, set
\[\mathbf{\eps} = \begin{pmatrix} a_1 & a_2 \end{pmatrix}^{\text{T}}.\]
We have 
\begin{align*}
R{\varepsilon}
	& = \begin{pmatrix} 
		\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} \cdot 
		 \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| \\ 
		\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_2} \cdot 
		 \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|
		 \end{pmatrix}.
\end{align*}
Since $R$ is invertible with $R^{-1} = (\overline{r}_{nm})$, we find
\begin{align*}
{\varepsilon} 
	& = \begin{pmatrix} 
		\overline{r}_{11}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} 		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| + 
		\overline{r}_{12}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}
		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right| \\
		\overline{r}_{21}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} 		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| +
		\overline{r}_{22}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}
		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|
		\end{pmatrix},
\end{align*}
giving
\[a_l = \overline{r}_{l1}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} 		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| + 
	\overline{r}_{l2}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}
	\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|\]
for $l = 1,2$. 

To estimate $|a_l|$, we begin to estimate the sum on the right hand side. For this, we consider
\[\frac{\delta_2}{\lambda}= \left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{a_2}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{n_i}.\]
For any embedding $\iota: L \to \mathbb{C}$, we have 
\[\left(\frac{\delta_2}{\lambda}\right)^{\iota} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{\iota \ n_i} =  \left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota \ a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota \ a_2}.\] 

Taking absolute values, we obtain
\[\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{\iota \ n_i}\right| = \left|\left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota \ a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota \ a_2}\right|,\]
so that
\begin{align*}
\log\left|\left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota \ a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota \ a_2}\right|
	& = \log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota}\right| - \log\left| \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{\iota \ n_i}\right|. 
\end{align*}

Hence, for $l =1,2$,
\begin{align*}
a_l	& = \overline{r}_{l1}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} 		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| + 
	\overline{r}_{l2}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}
	\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|\\
	& = \overline{r}_{l1}\left( \log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| - \log\left| \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{\iota_1 \ n_i}\right|\right) + \\ 
	& \quad \quad + \overline{r}_{l2}\left( \log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| - \log\left| \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{\iota_2 \ n_i}\right|\right)\\
	& = \overline{r}_{l1}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| + \overline{r}_{l2}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| - n_1\beta_{\gamma_1 l} - \dots - n_{\nu}\beta_{\gamma_{\nu} l},
\end{align*}
where
\[\beta_{\gamma_k l} = \left(\overline{r}_{l1} \log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_1}\right|+ \overline{r}_{l2}\log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_2}\right|\right)\]
for $k = 1, \dots, \nu$. Recall that $\mathbf{n} = A^{-1}(\mathbf{u} - \mathbf{r})$ and suppose $A^{-1} = (\overline{a}_{nm})$. We have
\begin{align*}
\mathbf{n}  = A^{-1}(\mathbf{u} - \mathbf{r})
	 = \begin{pmatrix} \sum_{k=1}^{\nu} \overline{a}_{1k}(u_k-r_k)\\  \vdots \\ \sum_{k=1}^{\nu} \overline{a}_{\nu k}(u_k-r_k) \end{pmatrix}.
\end{align*}

Now, 
\begin{align*}
a_l 	& = \overline{r}_{l1}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| + \overline{r}_{l2}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| - n_1\beta_{\gamma_1 l} - \dots - n_{\nu}\beta_{\gamma_{\nu} l}\\
	& = \overline{r}_{l1}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| + \overline{r}_{l2}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| - \sum_{k=1}^{\nu}(u_k-r_k)\alpha_{\gamma l k},
\end{align*}
where
\[\alpha_{\gamma l k} = \overline{a}_{1k}\beta_{\gamma_1 l} + \cdots + \overline{a}_{\nu k}\beta_{\gamma_{\nu} l}\]
and
\[\beta_{\gamma_k l} = \left(\overline{r}_{l1} \log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_1}\right|+ \overline{r}_{l2}\log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_2}\right|\right)\]
for $k = 1, \dots, \nu$.

Since $\frac{\delta_2}{\lambda}$ is a quotient of elements which are conjugate to one another, by taking the norm on $L$ of $\frac{\delta_2}{\lambda}$, we obtain $N\left(\frac{\delta_2}{\lambda}\right) = 1.$ On the other hand, by definition, we have 
\[1 = N\left(\frac{\delta_2}{\lambda}\right) = \prod_{\sigma: L \to \mathbb{C}} \sigma \left(\frac{\delta_2}{\lambda}\right).\]
Taking absolute values and logarithms, 
\[0 = \sum_{\sigma: L \to \mathbb{C}} \log\left|\sigma \left(\frac{\delta_2}{\lambda}\right)\right|\]
so that
\[-\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota}\right| = -\log\left|\iota \left(\frac{\delta_2}{\lambda}\right)\right| = \sum_{\shortstack{\footnotesize $\sigma: L \to \mathbb{C} $\\ \footnotesize $ \sigma \neq \iota$}} \log\left|\sigma \left(\frac{\delta_2}{\lambda}\right)\right|.\]

Consider
\begin{align*}
|a_l| 	& = \left|\overline{r}_{l1}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| + \overline{r}_{l2}\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| - \sum_{k=1}^{\nu}(u_k-r_k)\alpha_{\gamma l k}\right|\\
	& \leq |\overline{r}_{l1}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right|\right| + |\overline{r}_{l2}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|\right| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}

Suppose $\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| \geq 0$ and $\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| \geq 0$. Then, 
\begin{align*}
|a_l| 	& \leq |\overline{r}_{l1}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right|\right| + |\overline{r}_{l2}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|\right| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& = |\overline{r}_{l1}|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| + |\overline{r}_{l2}|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& \leq \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}|\log\max\left\{\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right|,1\right\} + \\
	& \quad \quad +\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\log\max\left\{\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|,1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	&  \leq \sum_{w: L \to \mathbb{C}}\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}|\log\max\left\{\left|w\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}
By Proposition \ref{prop:heightdecomp}, we obtain
\[|a_l| \leq b\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w:L\to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} +  \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\]
where
\[b =
\begin{cases}
2 & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
1 & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3.
\end{cases}\]

Alternatively, suppose that both $\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| < 0$ and $\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| < 0$. In this case,

\begin{align*}
|a_l| 	& \leq |\overline{r}_{l1}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right|\right| + |\overline{r}_{l2}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|\right| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& = |\overline{r}_{l1}|\sum_{\shortstack{\footnotesize $\sigma: L \to \mathbb{C} $\\ \footnotesize $ \sigma \neq \iota_1$}} \log\left|\sigma \left(\frac{\delta_2}{\lambda}\right)\right|+ |\overline{r}_{l2}|\left(-\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|\right) \\
	& \quad \quad + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}| \\
	& \leq \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\sum_{\shortstack{\footnotesize $\sigma: L \to \mathbb{C} $\\ \footnotesize $ \sigma \neq \iota_1$}} \log\left|\sigma \left(\frac{\delta_2}{\lambda}\right)\right| +\\
	& \quad \quad +\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\left(-\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|\right) + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& = \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\sum_{\shortstack{\footnotesize $w: L \to \mathbb{C} $\\ \footnotesize $ \sigma \neq \iota_1, \iota_2$}} \log\left|\sigma \left(\frac{\delta_2}{\lambda}\right)\right|  + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	&  \leq \sum_{w: L \to \mathbb{C}}\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}|\log\max\left\{\left|w\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}
Again, by Proposition \ref{prop:heightdecomp}, this becomes
\[|a_l| \leq b\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w:L\to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} +  \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\]
where
\[b =
\begin{cases}
2 & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
1 & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3.
\end{cases}\]

Lastly, if, without loss of generality, we have $\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right| < 0$ and $\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| \geq 0$, then
\begin{align*}
|a_l| 	& \leq |\overline{r}_{l1}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_1}\right|\right| + |\overline{r}_{l2}|\left|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right|\right| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& = |\overline{r}_{l1}|\sum_{\shortstack{\footnotesize $\sigma: L \to \mathbb{C} $\\ \footnotesize $ \sigma \neq \iota_1$}} \log\left|\sigma \left(\frac{\delta_2}{\lambda}\right)\right|+ |\overline{r}_{l2}|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& \leq \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\sum_{w: L \to \mathbb{C}} \log \max \left\{\left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} +  |\overline{r}_{l2}|\log\left|\left(\frac{\delta_2}{\lambda}\right)^{\iota_2}\right| \\
	&\quad \quad +\sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}| \\
	& \leq \sum_{w: L \to \mathbb{C}}\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}|\log\max\left\{\left|w\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\}  \\
	& \quad\quad + \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\log\max\left\{\left|\iota_2\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}
Applying Proposition \ref{prop:heightdecomp} yields
\begin{align*}
|a_l| & \leq b\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w:L\to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}\\
	& \quad \quad + \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\log\max\left\{\left|\iota_2\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}| \\
	& \leq \tilde{b} \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w:L\to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|
\end{align*}
where
\[\tilde{b} =
\begin{cases}
3 & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
2 & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3.
\end{cases}\]

In all three cases, it follows that
\begin{align*}
|a_l| & \leq \tilde{b} \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w:L\to \mathbb{C}} \log \max \left\{ \left|w\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|
\end{align*}
%|a_l|	& \leq \sum_{w: L \to \mathbb{C}}\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}|\log\max\left\{\left|w\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\} \\
%	&\quad\quad + |\overline{r}_{l1}|\log\max\left\{\left|\iota_1\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\} + |\overline{r}_{l2}|\log\max\left\{\left|\iota_2\left(\frac{\delta_2}{\lambda}\right)\right|,1\right\}\\
%	&\quad\quad+ \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|
%\end{align*}
where
\[\tilde{b} =
\begin{cases}
3 & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
2 & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3,
\end{cases}\]
\[\alpha_{\gamma l k} = \overline{a}_{1k}\beta_{\gamma_1 l} + \cdots + \overline{a}_{\nu k}\beta_{\gamma_{\nu} l},\]
and
\[\beta_{\gamma_k l} = \left(\overline{r}_{l1} \log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_1}\right|+ \overline{r}_{l2}\log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_2}\right|\right)\]
for $k = 1, \dots, \nu$.

Hence for $l = 1,2$, we write
\begin{align} \label{eq:albound}
%|a_l|	&\leq \frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon l \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
%	&\quad\quad+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|,
|a_l|	& \leq  w_{\varepsilon l} \frac{b}{[L:\mathbb{Q}]} \max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
	& \quad\quad+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|,
\end{align}
where
\begin{equation} \label{eq:welsigma}
w_{\varepsilon l} = \frac{\overline{b}\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}[L:\mathbb{Q}]}{b}
%w_{\varepsilon l \sigma} = 
%\begin{cases}
%\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}[L:\mathbb{Q}] & \text{ for } \sigma \notin I\\
%\left(\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\} + |\overline{r}_{li}|\right)[L:\mathbb{Q}] & \text{ for } \sigma = \iota_i \in I\\
%\end{cases}
\end{equation}
and 
\begin{equation} \label{eq:wgammalk}
w_{\gamma l k} = |\alpha_{\gamma l k}|\frac{[K:\mathbb{Q}]}{\log(p_k)}.
\end{equation}

To summarize, we have proven the following lemma.
\begin{lemma}\label{lem:mepsbound}
For any solution $(x,y,a_1, \dots, a_r, n_1, \dots, n_{\nu})$ of \eqref{eq:EfficientSunit}, for $l =1,2$
\begin{align*}
|a_l| & \leq  w_{\varepsilon l} \frac{b}{[L:\mathbb{Q}]} \max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
%&\leq \frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon l \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
	& \quad \quad+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|.
\end{align*}
\end{lemma}

%---------------------------------------------------------------------------------------------------------------------------------------------%

\subsection{The Archimedean ellipsoid: the real case}
\label{subsec:ArchEllipsoid}

Let $\tau:L\to\mathbb{R} \subset \mathbb{C}$ be an embedding and let $l_\tau\geq c_\tau$ and $c>0$ be given real numbers for $c_\tau=\log^+(2|\tau(\delta_2)|)= \log \max\{2|\tau(\delta_2)|,1\}$. We define 
\begin{equation} \label{eq:alpha0eps}
\alpha_0 = [c\log|\tau(\delta_1)|], \;  \; \alpha_{\varepsilon 1} =  \left[c\log\left|\tau\left(\frac{\varepsilon_1^{(k)}}{\varepsilon_1^{(j)}}\right)\right|\right],\ \  \alpha_{\varepsilon 2} =  \left[c\log\left|\tau\left(\frac{\varepsilon_2^{(k)}}{\varepsilon_2^{(j)}}\right)\right|\right].
\end{equation}
For $i = 1, \dots, \nu$, define
\begin{equation} \label{eq:alphagamma}
\alpha_{\gamma i} = \left[c\log\left|\tau\left(\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right|\right].
\end{equation}
Here, $[ \ \cdot\  ]$ denotes the nearest integer function. 

Let
\begin{equation} \label{eq:wsigma}
w_{\varepsilon} = (w_{\varepsilon 1} + w_{\varepsilon 2}), \quad \quad w_k = (w_{\gamma 1 k} + w_{\gamma 2 k}) + \frac{[K:\mathbb{Q}]}{\log(p_k)}\sum_{i=1}^{\nu}|\overline{a}_{ik}|
\end{equation}
for $k = 1, \dots, \nu$. Here $w_{\eps 1}, w_{\eps 2}$ and $w_{\gamma 1 k}, w_{\gamma 2 k}$ are the coefficients \eqref{eq:welsigma} and \eqref{eq:wgammalk}, respectively. Let $\kappa_{\tau} = 3/2$ and 
\[h_{\tau}\left(\frac{\delta_2}{\lambda}\right) = \frac{1}{[L:K]}\log \max \left\{ \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\},\]
the local height at $\tau$ in the decomposition of $h\left(\frac{\delta_2}{\lambda}\right)$.

\begin{lemma}\label{lem:archellest}
Suppose $(x,y, n_1, \dots, n_{\nu}, a_1, \dots, a_r)$ is a solution of \eqref{eq:EfficientSunit}. If ${h_{\tau} \left(\frac{\delta_2}{\lambda}\right) > c_{\tau}}$, then  
\begin{align*}
& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| \\
	& \quad \leq \frac{1}{2}\left(\frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}w_l \log(p_l)|u_l - r_l| + \frac{b}{[L:\mathbb{Q}]}w_{\varepsilon}\max_{\sigma :L \to \mathbb{C}} \log^+ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right| \right)\\
	&\quad\quad + \left(\frac{1}{2} + c\kappa_{\tau}e^{-h_{\tau}\left(\frac{\delta_2}{\lambda}\right)}\right).
\end{align*} 
\end{lemma}

\begin{proof}
Let 
\begin{align*}
\alpha	
	& = \alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\\
	& = [c\log|\tau(\delta_1)|] +\sum_{i = 1}^r a_i \left[c\log\left|\tau\left(\frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)\right|\right] + \sum_{i = 1}^{\nu} n_i \left[c\log\left|\tau\left(\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right|\right]
\end{align*}
and
\begin{align*}
\Lambda_{\tau} &= \log\left|\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right)\right|\\
&= \log\left(\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right)\right)
\end{align*}
where the above equality follows from 
\[\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right) > 0.\]
Indeed, by assumption,
\[ h_{\tau}\left(\frac{\delta_2}{\lambda}\right) > c_\tau = \log \max\{2|\tau(\delta_2)|,1\},\]
so that 
\begin{align*}
\exp\left(h_{\tau}\left(\frac{\delta_2}{\lambda}\right)\right)	& > \exp(c_{\tau}) \\
\exp\left(\log \max \left\{ \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}\right) & > \exp \left(\log \max\{2|\tau(\delta_2)|,1\}\right)\\
\max \left\{ \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} & > \max\{2|\tau(\delta_2)|,1\}.
\end{align*}
From this last inequality, we must have that 
\[\max \left\{ \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} = \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|.\]
In this case, 
\[\max\{2|\tau(\delta_2)|,1\} < \max \left\{ \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} = \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|.\]
It follows that
\[2|\tau(\delta_2)| \leq \max\{2|\tau(\delta_2)|,1\} < \max \left\{ \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} = \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right|\]
and therefore
\[2|\tau(\delta_2)| < \left|\tau\left(\frac{\delta_2}{\lambda}\right)\right| = \frac{|\tau(\delta_2)|}{|\tau(\lambda)|} \implies |\tau(\lambda)| < \frac{1}{2}.\]
Recall that $\delta_1\tilde{y} - \delta_2\tilde{x} = 1$. This is equation \eqref{eq:TrueSunit} defined earlier. In particular, observe that $\lambda = \delta_2\tilde{x}$, so that applying $\tau$, we obtain
\[\tau(\lambda) = \tau(\delta_2\tilde{x}) = \tau(\delta_1\tilde{y}) - 1.\]
Thus
\[|\tau(\lambda)| < \frac{1}{2} \implies \tau(\delta_1\tilde{y}) = \tau(\lambda) + 1 > 0.\]
This proves that
\[\tau(\delta_1\tilde{y}) = \tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right) > 0.\]
Having established this, we write, 
\begin{align*}
\Lambda_{\tau} &= \log\left|\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right)\right|\\
&= \log\left(\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right)\right)
\end{align*}
or equivalently, 
\begin{align*}
\Lambda_{\tau}	
	& = \log\left(\tau\left(\delta_1\right)\right) + \sum_{i=1}^r a_i\log\left(\tau\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right) \right) + \sum_{i=1}^{\nu}n_i\log \left(\tau\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right).
\end{align*}
By the triangle inequality, 
\[|\alpha| \leq |\alpha - c\Lambda_{\tau}| + c|\Lambda_{\tau}|,\]
where
\begin{align*}
|\alpha-c\Lambda_\tau|
	& = \left|[c\log(\tau(\delta_1))] +\sum_{i = 1}^r a_i \left[c\log\left(\tau\left(\frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)\right)\right] \right.\\
	& \quad \quad \left. + \sum_{i = 1}^{\nu} n_i \left[c\log\left(\tau\left(\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right)\right] \right. \\
	&\quad\quad \left.- c \log\left(\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right)\right)\right|\\
	& \leq \left| [c\log(\tau(\delta_1))] - c\log\left(\tau\left(\delta_1\right)\right)\right| \\
	& \quad \quad  + \sum_{i = 1}^r |a_i|\left| \left[c\log\left(\tau\left(\frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)\right)\right] - c\log\left(\tau\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right) \right)\right|\\
	& \quad \quad +  \sum_{i = 1}^{\nu} |n_i|\left| \left[c\log\left(\tau\left(\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right)\right] - c\log \left(\tau\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right)\right|.
\end{align*}
Since $[ \ \cdot \ ]$ denotes the nearest integer function, it is clear that $|[ \ c \ ] - c| \leq 1/2$ for any integer $c$, 
\begin{align*}
|\alpha-c\Lambda_\tau|
	& \leq \frac{1}{2} + \frac{1}{2}\sum_{i = 1}^r |a_i| + \frac{1}{2}\sum_{i = 1}^{\nu} |n_i|\\
	& \leq \frac{1}{2}\left(1 + \sum_{i = 1}^r |a_i| + |u_1-r_1|\sum_{i=1}^{\nu}|\overline{a}_{i1}| + \cdots + |u_{\nu} - r_{\nu}| \sum_{i=1}^{\nu}|\overline{a}_{i\nu}|\right).
\end{align*}
By Lemma~\ref{lem:mepsbound}, 
\begin{align*}
|a_l| & \leq  w_{\varepsilon l} \frac{b}{[L:\mathbb{Q}]} \max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
	& \quad \quad+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|.
%|a_l| &\leq \frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon l \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
%	& \quad \quad+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|
\end{align*}
for $l = 1,2$. Applying this result to $|\alpha-c\Lambda_\tau|$, we obtain
\begin{align*}
|\alpha-c\Lambda_\tau| 
	& \leq \frac{1}{2} + \frac{1}{2}|u_1-r_1|\sum_{i=1}^{\nu}|\overline{a}_{i1}| + \cdots + \frac{1}{2}|u_{\nu} - r_{\nu}| \sum_{i=1}^{\nu}|\overline{a}_{i\nu}| + \\
	& \quad + \frac{1}{2}\left(w_{\varepsilon 1} \frac{b}{[L:\mathbb{Q}]} \max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}\right. \\
	& \quad \quad \left.+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma 1 k}\log(p_k)|u_k - r_k|\right) + \\
%	& \quad + \frac{1}{2}\left(\frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon_1 \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \right.\\
%	&\quad\quad \left.+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma_1 k}\log(p_k)|u_k - r_k| \right) + \\
	& \quad + \frac{1}{2}\left(w_{\varepsilon 2} \frac{b}{[L:\mathbb{Q}]} \max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\}\right. \\
	& \quad \quad \left.+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma 2 k}\log(p_k)|u_k - r_k|\right) \\
%	&\quad + \frac{1}{2}\left(\frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon_2 \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \right.\\
%	&\quad\quad \left.+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma_2 k}\log(p_k)|u_k - r_k| \right) \\
	& = \frac{1}{2} + (w_{\varepsilon 1} + w_{\varepsilon_2})\frac{b}{2[L:\mathbb{Q}]}\max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} + \\
	& \quad + |u_1 - r_1|\left( \frac{(w_{\gamma 1 1} + w_{\gamma 2 1})}{2[K:\mathbb{Q}]}\log(p_1) + \frac{1}{2}\sum_{i=1}^{\nu}|\overline{a}_{i1}|\right) + \cdots \\
	& \quad + |u_{\nu} - r_{\nu}|\left( \frac{(w_{\gamma 1 {\nu}} + w_{\gamma 2 {\nu}})}{2[K:\mathbb{Q}]}\log(p_{\nu}) + \frac{1}{2}\sum_{i=1}^{\nu}|\overline{a}_{i{\nu}}|\right). 
\end{align*}
Altogether, we have
\begin{align*}
& |\alpha-c\Lambda_\tau| \\
	& \quad \leq \frac{1}{2} + \frac{b}{2[L:\mathbb{Q}]}(w_{\varepsilon 1} + w_{\varepsilon 2})\max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
	& \quad \quad+ \frac{1}{2[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} \log(p_k)|u_k - r_k|\left( (w_{\gamma 1 k} + w_{\gamma 2 k}) + \frac{[K:\mathbb{Q}]}{\log(p_k)}\sum_{i=1}^{\nu}|\overline{a}_{ik}|\right).
\end{align*}
Finally, using the notation of \eqref{eq:wsigma}, this inequality reduces to
\begin{align*}
|\alpha-c\Lambda_\tau|
	& \leq \frac{1}{2} + \frac{b}{2[L:\mathbb{Q}]} w_{\varepsilon}\max_{\sigma :L \to \mathbb{C}}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
	&\quad\quad + \frac{1}{2[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}w_l \log(p_l)|u_l - r_l|.
\end{align*}

Now the following upper bound for $|\Lambda_\tau|$ implies the statement. On using power series definition of exponential function, we obtain $$\Lambda_\tau(1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!)=\Lambda_\tau+\sum_{n\geq 2} (\Lambda_\tau)^n/n!=e^{\Lambda_\tau}-1=\tau(\lambda).$$
If $\Lambda_\tau\geq 0$ then $1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!>1$ which implies that $|\Lambda_\tau|\leq |\tau(\lambda)|.$ Suppose now that $\Lambda_\tau<0$. Our assumption $h_{\tau}(z)\geq \log^+ (2|\lambda_0|)$ means that $|\tau(\lambda)|\leq 1/2$ and thus $|\Lambda_\tau|=-\log (\tau(\lambda)+1)\leq -\log(1/2)=\log 2.$ Therefore, the absolute value of $\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!$ is at most $$\sum_{n\geq 2} |\Lambda_\tau|^{n-1}/n!=\sum_{n\geq 1} |\Lambda_\tau|^{n}/(n+1)!\leq \tfrac{1}{2}\sum_{n\geq 1} |\Lambda_\tau|^{n}/n!\leq
\tfrac{1}{2}e^{\log 2}-1/2=1/2.$$
More precisely, for any even $N\geq 2$, we obtain 
\begin{align*}
|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|
	& =|\sum_{n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|\\
	&\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}|\sum_{n>N} (\Lambda_\tau)^{n}/n!|\\
	&\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}e^{|\Lambda_\tau|}\\
	& \leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{2}{N+2}:=k_N.
\end{align*}
We now give an upper bound for $k_N$. Since $\Lambda_\tau<0$, we obtain
$$\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!=\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^n}{(n+1)!}-\tfrac{|\Lambda_\tau|^{n-1}}{n!}$$
$$=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)=\tfrac{|\Lambda_\tau|}{2}(\tfrac{|\Lambda_\tau|}{3}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)$$
$$\geq \tfrac{\log 2}{2}(\tfrac{\log 2}{4}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{(\log 2)^{n-1}}{n!}(\tfrac{3/4(\log 2)}{n+1}-1):=-k_N.$$
The last inequality follows by distinguishing two cases whether  $|\Lambda_\tau|\leq 3/4\cdot \log 2$ or not; note that $\ln(2)/2\cdot(\ln(2)/4-1)/(-\ln (2)\cdot3/8)\geq 1$.  Now, on using that $-k_N$ is negative, it follows that 
\[|1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-k_N\]
and thus 
$$|\Lambda_\tau|\leq \kappa_\tau|\tau(x)|, \quad \kappa_\tau=\tfrac{1}{1-k_N}|\tau(\lambda_0)|,  \quad c_\tau=\log^+(2|\lambda_0|).$$
The constant $\kappa_\tau$ depends on $N$ which can be taken arbitrarily as long as $N\geq 2$ is even. Further, the value $k_N$ can be slightly improved when one finds the maximum of the functions $x^{n-1}(\tfrac{x}{n+1}-1)$ on the interval $[0,\log 2]$ for each even $n\geq 2$. This is our reason for taking $\kappa_{\tau} = \frac{3}{2}$. Currently this is not the optimal choice of $\kappa_{\tau}$, but it suffices for our present case. 

Finally, we now have
\begin{align*}
& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| \\
	& \quad \leq \frac{1}{2}\left(\frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}w_l \log(p_l)|u_l - r_l| + \frac{b}{[L:\mathbb{Q}]}w_{\varepsilon}\max_{\sigma :L \to \mathbb{C}} \log^+ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right| \right)\\
	&\quad\quad + \left(\frac{1}{2} + c\kappa_{\tau}e^{-h_{\tau}\left(\frac{\delta_2}{\lambda}\right)}\right).
\end{align*} 

%
%If $v=p$ then Lemma~\ref{} gives optimal $c_v$ and $\kappa_v$. In the real case, if $v=\tau:L\to \mathbb{C}$ then we can take $\kappa_\tau$ as defined in \eqref{} and $c_v=\log 2$.
%
%Let now  $v=\tau$. Suppose first that we are in the real case. It holds that $\mu-1=\lambda$ and $\Lambda_\tau=\log \tau (\mu)$. Then, on using power series definition of exponential function, we obtain $$\Lambda_\tau(1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!)=\Lambda_\tau+\sum_{n\geq 2} (\Lambda_\tau)^n/n!=e^{\Lambda_\tau}-1=\tau(\lambda).$$
%If $\Lambda_\tau\geq 0$ then $1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!>1$ which implies that $|\Lambda_\tau|\leq |\tau(\lambda)|.$ Suppose now that $\Lambda_\tau<0$. Our assumption $h_v(z)\geq \log 2$ means that $|\tau(z)|\leq 1/2$ and thus $|\Lambda_\tau|=-\log (\tau(z)+1)\leq -\log(1/2)=\log 2.$ Therefore, the absolute value of $\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!$ is at most $$\sum_{n\geq 2} |\Lambda_\tau|^{n-1}/n!=\sum_{n\geq 1} |\Lambda_\tau|^{n}/(n+1)!\leq \tfrac{1}{2}\sum_{n\geq 1} |\Lambda_\tau|^{n}/n!\leq
%\tfrac{1}{2}e^{\log 2}-1/2=1/2.$$
%More precisely, for any even $N\geq 2$, we obtain 
%$$|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|=|\sum_{n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}|\sum_{n>N} (\Lambda_\tau)^{n}/n!|$$
%$$\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}e^{|\Lambda_\tau|}\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{2}{N+2}:=k_N.$$
%We now give an upper bound for $k_N$. Since $\Lambda_\tau<0$, we obtain
%$$\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!=\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^n}{(n+1)!}-\tfrac{|\Lambda_\tau|^{n-1}}{n!}$$
%$$=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)=\tfrac{|\Lambda_\tau|}{2}(\tfrac{|\Lambda_\tau|}{3}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)$$
%$$\geq \tfrac{\log 2}{2}(\tfrac{\log 2}{4}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{(\log 2)^{n-1}}{n!}(\tfrac{3/4(\log 2)}{n+1}-1):=-k_N.$$
%The last inequality follows by distinguishing two cases whether  $|\Lambda_\tau|\leq 3/4\cdot \log 2$ or not; note that $ln(2)/2*(ln(2)/4-1)/(-ln (2)*3/8)\geq 1$.  Now, on using that $-k_N$ is negative, it follows that $|1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-k_N$ and thus 
%$$|\Lambda_\tau|\leq \kappa_\tau|\tau(z)|, \quad \kappa_\tau=\tfrac{1}{1-k_N},  \quad c_\tau=\log 2.$$
%The constant $\kappa_\tau$ depends on $N$ which can be taken arbitrarily as long as $N\geq 2$ is even. Further, the value $k_N$ can be slightly improved when one finds the maximum of the functions $x^{n-1}(\tfrac{x}{n+1}-1)$ on the interval $[0,\log 2]$ for each even $n\geq 2$. 
\end{proof}

To summarize the results of this section, let $\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}$ be any solution of \eqref{eq:EfficientSunit} with corresponding vector $\mathbf{n} = (n_1, \dots, n_{\nu})$. Take $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu+m}$ such that $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ and suppose $h_v(z)\leq h_v$ for all $v\in S^*$. By Lemma~\ref{lem:boundqf}, we deduce
\begin{equation} \label{def:bbound}
\log(2)^2q_f(\mathbf{n}) \leq \sum_{k = 1}^{\nu} \log(p_k)^2|u_k -r_k|^2 \leq \sum_{k = 1}^{\nu} h_k^2=:b.
\end{equation}
For $l = 1, 2$, Lemma~\ref{lem:mepsbound} gives us
\begin{align}\label{def:bepsbound}
|a_l|^2 &\leq \left(\frac{b}{[L:\mathbb{Q}]}w_{\varepsilon l}\max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \right.\\
	& \quad \quad+ \left. \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|\right)^2\\
	&\leq \left( \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}h_k + \frac{b}{[K:\mathbb{Q}]}w_{\varepsilon l}\max_{\sigma:L\to \mathbb{C}} h_{\sigma}\right)^2 =: b_{\eps_l}.
\end{align}
Finally, suppose in addition that
\[h_{\tau}\left(\frac{\delta_2}{\lambda}\right) \geq l_{\tau} > c_{\tau}.\]
Then by Lemma~\ref{lem:archellest}, we obtain
\begin{align*}
& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| \\
	& \quad \leq \frac{1}{2}\left(\frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}w_l \log(p_l)|u_l - r_l| + \frac{b}{[L:\mathbb{Q}]}w_{\varepsilon}\max_{\sigma :L \to \mathbb{C}} \log^+ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right| \right)\\
	&\quad\quad + \left(\frac{1}{2} + c\kappa_{\tau}e^{-h_{\tau}\left(\frac{\delta_2}{\lambda}\right)}\right)\\
	& \quad \leq \frac{1}{2}\left(\frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}w_l h_l + \frac{b}{[K:\mathbb{Q}]}w_{\eps}\max_{\sigma :L \to \mathbb{C}}h_{\sigma} \right) + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}, 
\end{align*} 
and we set
\begin{equation} \label{def:bepstarbound}
b_{\eps_l^*}:= \frac{1}{2}\left(\frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}w_l h_l + \frac{b}{[K:\mathbb{Q}]}w_{\varepsilon}\sum_{\sigma :L \to \mathbb{C}} h_{\sigma} \right) + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}.
\end{equation}

It is of particular importance to note that the assumptions $h_{\tau}(z) \geq l_{\tau}$ and  $h_v(z)\leq h_v$ for all $v\in S^*$ are not arbitrary. Indeed, for the vectors $\mathbf{l}, \mathbf{h}$, these conditions imply precisely that $(\tilde{x},\tilde{y}) \in \Sigma_{\tau}(\mathbf{l}, \mathbf{h})$, where $(\tilde{x},\tilde{y})$ are solutions to \eqref{eq:EfficientSunit} corresponding to $\mathbf{m}$.


%
%\begin{align*}
%& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| ^2 \\ & \leq
%\begin{cases}
%\left( \frac{2}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\notin\mathbb{Q} \\
%\left( \frac{1}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\in\mathbb{Q}.\\
%\end{cases}
%\end{align*}

%We now fix $\epsilon^*\in\unit_\infty$ and we take $h\in\RR^{S^*}$ with $h\geq 0$.  Let $(x,y)\in\Sigma$ with $m\in\ZZ^\unit$ and $h_\tau(z)\geq l_\tau$, and suppose that $h_v(z)\leq h_v$ for all $v\in S^*$. Then, on combining Lemma~\ref{lem:archellest} with \eqref{eq:hvjbound}, we see that  $\left|\alpha_0+\sum_{u\in\unit}m_u\alpha_u\right|^2$ is at most
%\begin{equation}\label{def:bepsstarbound}
%b_{\epsilon^*}=\left(\sum_{v:L\to\CC}w_{v}h_v+\sum_{v\in T}\max\bigl(w_{v}h_v,w_{v^{(j)}}a_p\log N(v^{(j)})\bigl)+c\kappa_\tau e^{-l_{\tau}}\right)^2.
%\end{equation}
%By Remark~\ref{rem:i12}, we can replace $\sum_{v:L\to\CC}w_{v}h_v$ by $3[L:K]\|r_\epsilon\|_\infty\max_{v:L\to\CC}h_v$ if $|I|=2$.
%

We are finally in position to define the ellipsoid corresponding to $\Sigma_{\tau}(\mathbf{l}, \mathbf{h})$. Fix any $\eps_l^* \in \{\varepsilon_1, \dots, \varepsilon_r\}$. 
For each $\varepsilon_l$ in $\{\varepsilon_1, \dots, \varepsilon_r\}$ such that $\varepsilon_l \neq \varepsilon_l^*$, we associate the bound $b_{\eps_l}$. For $\varepsilon_l$, we associate the value $b_{\eps_l^*}$.
%
%\[b_{\varepsilon_l} = 
%\begin{cases}
%\left( \frac{2}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\notin\mathbb{Q} \\
%\left( \frac{1}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\in\mathbb{Q}\\
%\end{cases}\]
%where
%\begin{align*}
%\left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \right.& \left.\sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| ^2 
%	\leq b_{\varepsilon_l} \\
%\\ & =
%\begin{cases}
%\left( \frac{2}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\notin\mathbb{Q} \\
%\left( \frac{1}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\in\mathbb{Q}.\\
%\end{cases}
%\end{align*}

Let
\[\mathbf{x} = (x_1, \dots, x_{\nu}, x_{\varepsilon_1}, \dots, x_{\varepsilon_{r}}) \in \mathbb{R}^{\nu + r}.\]
Then we define the ellipsoid $\mathcal{E_\tau}\subseteq \mathbb{R}^{r+\nu}$ by
\begin{align}\label{def:ellreal}
& \mathcal{E_\tau}=\{q_\tau(\mathbf{x})\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}); \ \mathbf{x}\in\mathbb{R}^{r+\nu}\}\end{align}
where
\[q_{\tau}(\mathbf{x})= (b_{\varepsilon_1}\cdots b_{\varepsilon_r})\left( q_f(x_1, \dots, x_{\nu}) + \sum_{i = 1}^r\frac{b}{b_{\varepsilon_i}}x_{\varepsilon_i}^2\right)\]
and
\[q_f(\mathbf{y}) = (A\mathbf{y})^{\text{T}}D^2A\mathbf{y}.\]

We associate to this ellipsoid a matrix. More precisely, we let $M=M_\tau$ be the matrix defining the ellipsoid $\mathcal{E}_{\tau}$. Explicitly, this is the matrix
\begin{align*}
M &=\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
	DA & 0 & \dots & 0 & 0\\
	0 & \sqrt{\frac{b}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
	0 & 0  & \sqrt{\frac{b}{b_{\varepsilon 2}}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\ 
	0 & 0 & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon^*}}} \\
	\end{pmatrix}.
\end{align*}	
Note that we never need to compute $M$, but rather $M^TM$ so that we only ever work with integral matrices. In this case, 
\begin{align*}
M^TM &= b_{\varepsilon_1}\cdots b_{\varepsilon_r}\begin{pmatrix}
	A^TD^2A & 0 & \dots & 0 & 0\\
	0 & \frac{b}{b_{\varepsilon 1}} & \dots & 0 & 0\\
	0 & 0  & \frac{b}{b_{\varepsilon 2}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\ 
	0 & 0 & \dots & \dots & \frac{b}{b_{\varepsilon^*}} \\
	\end{pmatrix}.
\end{align*}	


%---------------------------------------------------------------------------------------------------------------------------------------------%

\subsection{The non-Archimedean ellipsoid}
\label{subsec:nonArchEllipsoid}

We now restrict our attention to those $p_v \in \{p_1, \dots, p_{\nu}\}$ and define the corresponding ellipsoid. As before, let $\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}$ be any solution of \eqref{eq:EfficientSunit} with corresponding vector $\mathbf{n} = (n_1, \dots, n_{\nu})$. Take $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu+m}$ such that $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ and suppose $h_v(z)\leq h_v$ for all $v\in S^*$. 

Now, Lemma~\ref{lem:boundqf} and Lemma~\ref{lem:mepsbound} still hold here. In particular, we let $b$, $b_{\eps_l}$ be defined as in \eqref{def:bbound} and \eqref{def:bepsbound}, respectively, where $l = 1, \dots, r$. We do not distinguish any $\varepsilon_l^*$. Instead, we will see later that the condition $h_{v}(z) \geq l_{v}$ corresponding to the set $\Sigma_v(\mathbf{l}, \mathbf{h})$ will be used elsewhere. 

We define the ellipsoid $\mathcal{E}_v \subseteq \mathbb{R}^{\nu + r}$ by 
\begin{align}\label{def:ellp}
& \mathcal{E}_v=\{q_l(\mathbf{x})\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}); \ \mathbf{x}\in\mathbb{R}^{r+\nu}\},\end{align}
where
\[q_v(\mathbf{x})= (b_{\varepsilon_1}\cdots b_{\varepsilon_r})\left( q_f(x_1, \dots, x_{\nu}) + \sum_{i = 1}^r\frac{b}{b_{\varepsilon_i}}x_{\varepsilon_i}^2\right)\]
and
\[q_f(\mathbf{y}) = (A\mathbf{y})^{\text{T}}D^2A\mathbf{y}.\]

Similar to the Archimedean case, we let $M=M_v$ be the matrix defining the ellipsoid $\mathcal{E}_{v}$. Explicitly, this is the matrix
\begin{align*}
M &=\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
	DA & 0 & \dots & 0 & 0\\
	0 & \sqrt{\frac{b}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
	0 & 0  & \sqrt{\frac{b}{b_{\varepsilon 2}}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\ 
	0 & 0 & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon}}} \\
	\end{pmatrix}.
\end{align*}	
As before, we never need to compute $M$, but rather $M^TM$ so that we only ever work with integral matrices. In this case, 
\begin{align*}
M^TM &= b_{\varepsilon_1}\cdots b_{\varepsilon_r}\begin{pmatrix}
	A^TD^2A & 0 & \dots & 0 & 0\\
	0 & \frac{b}{b_{\varepsilon 1}} & \dots & 0 & 0\\
	0 & 0  & \frac{b}{b_{\varepsilon 2}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\ 
	0 & 0 & \dots & \dots & \frac{b}{b_{\varepsilon}} \\
	\end{pmatrix}.
\end{align*}	


%---------------------------------------------------------------------------------------------------------------------------------------------%

\section{The Archimedean sieve: the real case}
\label{sec:archsieve}

Let $\tau:L\to\mathbb{C}$ be an embedding. We take $\mathbf{l},\mathbf{h} \in \mathbb{R}^{m+\nu}$ with $\mathbf{0}\leq \mathbf{l}\leq \mathbf{h}$ and $l_\tau\geq \log 2$. Let $c$ be a constant the size of $e^{l_\tau}$ and let $\alpha_0, \alpha_{\varepsilon 1}, \dots, \alpha_{\varepsilon {r}}, \alpha_{\gamma 1}, \dots, \alpha_{\gamma {\nu}}$ be defined as in \eqref{eq:alpha0eps} and \eqref{eq:alphagamma}. 

Define the $(\nu+r) \times (\nu +r)$-dimensional matrix $A_{\tau}$ as
\[A_{\tau} = \begin{pmatrix}
	1 & 0 & \dots &  \dots & 0 & 0\\ 
	0 & 1	& \dots & \dots & 0 & 0\\
	\vdots & \vdots & \ddots & \dots & \vdots & \vdots \\ 
	0 & 0 & \dots &  \dots & 1 & 0\\ 
	\alpha_{\gamma 1} & \dots &\alpha_{\gamma {\nu}} & \alpha_{\varepsilon 1} & \dots & \alpha_{\varepsilon {r}}
\end{pmatrix}\]
and consider the lattice defined by its columns. Let $\mathbf{w} = (0,\dotsc,0,\alpha_0)$ be a vector of length $(\nu + r)$. We now consider the translated lattice $\Gamma_{\tau}$ defined by $A_{\tau}\mathbf{x} + \mathbf{w}$, where $\mathbf{x}$ is an arbitrary coordinate vector. 
 
%for some fixed $\epsilon^*\in\unit_\infty$ and whose row indexed by $\epsilon^*$ is given by $(\alpha_u)\in\ZZ^\unit$. 
Let $\mathcal E_{\tau}=\mathcal E_{\tau}(h,l_{\tau})$ be the ellipsoid constructed in \eqref{def:ellreal}. Let 
\[\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}\]
be any solution of \eqref{eq:EfficientSunit}. We say that $\mathbf{m}$ is determined by some $\mathbf{y} \in \Gamma_{\tau}$ if 
\[\mathbf{y} = (y_1, \dots, y_{r+ \nu}) = \left(n_1, \dots, n_{\nu}, a_1, \dots, a_{r-1}, \alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right)\]
where the missing element $a_{l}$ corresponds to $\varepsilon_l^*$.

\begin{lemma}\label{lem:archsieve}
Let ${\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}}$ be any solution of \eqref{eq:EfficientSunit} which lies in $\Sigma_\tau(l,h)$. Then $\mathbf{m}$ is determined by some $\mathbf{y}\in \Gamma_\tau\cap\mathcal E_\tau.$
\end{lemma}

\begin{proof}
Let 
\[\mathbf{y} = \left(n_1, \dots, n_{\nu}, a_1, \dots, a_{r-1}, \alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right).\]
Then $\mathbf{y} \in \Gamma_\tau$ and \eqref{def:bepstarbound} implies that $y_{\eps_l^*}^2\leq b_{\eps_l^*}$. Further $q_f(y_1, \dots, y_{\nu})\leq b$ by \eqref{def:bbound} and \eqref{def:bepsbound} provides that $y_{\eps_l}^2\leq b_{\eps_l}$ for $l = 1, \dots, r$ with $\eps_l \neq \eps_l^*$. It follows that 
\[q_\tau(\mathbf{y}) = (b_{\varepsilon_1}\cdots b_{\varepsilon_r})\left( q_f(y_1, \dots, y_{\nu}) + \sum_{i = 1}^r\frac{b}{b_{\varepsilon_i}}y_{\varepsilon_i}^2\right) \leq (1+r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
This proves that $\mathbf{y}\in\mathcal E_\tau$ and hence the statement follows.
\end{proof}
%
We now explicitly determine $ \Gamma_\tau\cap \mathcal E_\tau$. Suppose that $\mathbf{y}\in \Gamma_\tau\cap \mathcal E_\tau$. Let $M=M_\tau$ be the matrix defining the ellipsoid $\mathcal{E}_{\tau}$. 	
Since $\mathbf{y}\in \Gamma_\tau\cap \mathcal E_\tau$, there exists $\mathbf{x}\in \mathbb{R}^{r + \nu}$ such that $\mathbf{y}= A_\tau \mathbf{x}+\mathbf{w}$ and ${\mathbf{y}^tM^tM\mathbf{y}\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})}$. We thus have
\[(A_\tau \mathbf{x}+\mathbf{w})^tM^tM(A_\tau \mathbf{x}+\mathbf{w}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
As $A_{\tau}$ is clearly invertible, with matrix inverse
\[A_{\tau}^{-1} = \begin{pmatrix}
	1 & 0 & \dots &  \dots & 0 & 0\\ 
	0 & 1	& \dots & \dots & 0 & 0\\
	\vdots & \vdots & \ddots & \dots & \vdots & \vdots \\ 
	0 & 0 & \dots &  \dots & 1 & 0\\ 
	-\frac{\alpha_{\gamma 1}}{\alpha_{\varepsilon {r}}} & \dots &-\frac{\alpha_{\gamma {\nu}}}{\alpha_{\varepsilon {r}}} & -\frac{\alpha_{\varepsilon 1}}{\alpha_{\varepsilon {r}}} & \dots & \frac{1}{\alpha_{\varepsilon {r}}}
\end{pmatrix},\]
we can find a vector $\mathbf{c}$ such that $A_{\tau}\mathbf{c} = -\mathbf{w}$. Indeed, this vector is
\[\mathbf{c} = A_{\tau}^{-1}\mathbf{w} =\begin{pmatrix}
	0 \\ 0 \\ \vdots \\ 0 \\ -\frac{\alpha_0}{\alpha_{\varepsilon r}}
\end{pmatrix}.\]
Now, 
\begin{align*}
(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
	& \geq (A_\tau \mathbf{x}+\mathbf{w})^tM^tM(A_\tau \mathbf{x}+\mathbf{w}) \\
	& = (A_\tau (\mathbf{x}-\mathbf{c}))^TM^TM(A_\tau (\mathbf{x}-\mathbf{c}))\\
	& = (\mathbf{x}-\mathbf{c})^T(MA_{\tau})^TMA_\tau(\mathbf{x}-\mathbf{c})\\
	& = (\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c})
\end{align*}
where $B = MA_\tau$. That is, we are left to solve
\[(\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
Now, finding all vectors satisfying this inequality amounts to computing all solutions to \eqref{eq:EfficientSunit} contained in $\Sigma_{\tau}(\mathbf{l}, \mathbf{h})$. The set of vectors $\mathbf{x}$ can be found using the Fincke-Pohst algorithm outlined in \autoref{subsec:FinckePohst}. 
%Here we observe that the vector $c$ is likely not an integral vector; that is, $-\frac{\alpha_0}{\alpha_{\varepsilon r}} \notin \mathbb{Z}$. To amend this, we modify the bound as follows
%\begin{align*}
%\alpha_{\varepsilon r}^2(x-c)^tB^tB(x-c) & \leq \alpha_{\varepsilon r}^2(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})\\
%(\alpha_{\varepsilon r}x-\alpha_{\varepsilon r}c)^tB^tB(\alpha_{\varepsilon r}x-\alpha_{\varepsilon r}c) & \leq \alpha_{\varepsilon r}^2(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})\\
%(z-d)^tB^tB(z-d) & \leq \alpha_{\varepsilon r}^2(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
%\end{align*}
%where $d = (0 \dots 0 -\alpha_0)$ and $z = \alpha_{\varepsilon r}x$. 
%Is this necessary? Our thing should work over the rationals regardless


%---------------------------------------------------------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------------------------------------------------------%

%
%
%
%
%
%
% Since
%\[M\gamma=M(\Gamma_\tau x+w) = M\Gamma_{\tau} x + Mw.\]
%Here, it is clear that $M$ is invertible, with inverse
%
%
%
%, it is also invertible. Hence we can find a vector $c$ such that $Bc = v$. 
%
%\begin{align*}
%B = &M\Gamma_{\tau} =\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
%	DA & 0 & \dots & 0 & 0\\
%	0 & \sqrt{\frac{b}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
%	0 & 0  & \sqrt{\frac{b}{b_{\varepsilon 2}}} & \dots & 0\\
%	\vdots & \vdots &0 &  \ddots & \vdots\\ 
%	0 & 0 & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon^*}}} \\
%	\end{pmatrix}
%	\begin{pmatrix}
%	1 & 0 & \dots &  \dots & \dots & 0 & 0\\ 
%	0 & 1	& \dots & \dots & \dots & 0 & 0\\
%	\vdots & \vdots & \ddots & \dots & \dots & \vdots & \vdots \\ 
%	0 & 0 & \dots &  \dots & \dots & 1 & 0\\ 
%	\alpha_0 & \alpha_{\gamma 1} & \dots &\alpha_{\gamma {\nu}} & \alpha_{\varepsilon 1} & \dots & \alpha_{\varepsilon^*}
%	\end{pmatrix}\\
%& = \sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
%	DA & \dots & \dots & \dots& 0 & 0\\
%	 0  & \sqrt{\frac{b}{b_{\varepsilon 1}}}& \dots & \dots & \vdots & \vdots \\
%	\vdots & \vdots &\vdots & \ddots & \vdots & \vdots\\ 
%	0 & 0  & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon r-1}}} &0\\
%	\alpha_0 \sqrt{\frac{b}{b_{\varepsilon^*}}}  & \dots & \dots & \alpha_{\varepsilon 1}\sqrt{\frac{b}{b_{\varepsilon^*}}} & \dots & \alpha_{\varepsilon^*}\sqrt{\frac{b}{b_{\varepsilon^*}}}
%	\end{pmatrix}\\
%	& =\begin{pmatrix}
%	 \sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}DA & \dots & \dots & \dots& 0 & 0\\
%	 0  &  \sqrt{bb_{\varepsilon_2}\cdots b_{\varepsilon_r}}& \dots & \dots & \vdots & \vdots \\
%	\vdots & \vdots &\vdots & \ddots & \vdots & \vdots\\ 
%	0 & 0  & \dots & \dots &  \sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-2}}b_{\varepsilon_{r}}} &0\\
%	\alpha_0 \sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}}}  & \dots & \dots & \alpha_{\varepsilon 1}\sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}}} & \dots & \alpha_{\varepsilon^*}\sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}}}
%	\end{pmatrix}.
%\end{align*}
%
%It follows that
%\begin{align*}
%(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})	
%	& \geq \gamma^tM^tM\gamma \\
%	& = (M\gamma)^tM\gamma \\
%	& = (Bx + v)^t(Bx + v).
%%	& = ((Bx)^t+v^t)(Bx+v)\\
%%	& = (x^tB^t + v^t)(Bx+v)\\
%%	& = x^tB^tBx + (Bx)^tv+v^tBx+v^tv.
%\end{align*}
%Now, since $B$ is positive-definite, it is also invertible. Hence we can find a vector $c$ such that $Bc = v$. 
%
%Now, 
%\[(Bx)^tv = (M\gamma - v)^tv = (M\gamma)^tv -v^tv\]
%and
%\[v^tBx = v^t(M\gamma - v) = v^t(M\gamma) -v^tv\]
%and thus
%\begin{align*}
%(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
%	& \geq x^tB^tBx + (Bx)^tv+v^tBx+v^tv\\
%	& = x^tB^tBx + (M\gamma)^tv -v^tv + v^t(M\gamma) -v^tv +v^tv\\
%	& = x^tB^tBx + (M\gamma)^tv + v^t(M\gamma) -v^tv \\
%	& = x^tB^tBx + 2(v^t(M\gamma)) -v^tv.
%\end{align*}
%Next, we observe that
%\begin{align*}
%|v^t(M\gamma)|
%	& = |(Mw)^t(M\gamma)|\\
%	& = |wM^TM\gamma|\\
%	& = |\alpha_0 bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}} \gamma_n|\\
%	& \leq |\alpha_0| bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}} \sqrt{b_{\varepsilon}^*},
%\end{align*}
%%
%%
%%\[|v^t(M\gamma)| \leq \frac{b}{b_{\epsilon^*}^{1/2}}|\alpha_0|\]
%and thus
%\[x^tB^tBx\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+v^tv - 2v^t(M\gamma)\]
%so that 
%\begin{align*}
%|x^tB^tBx| 
%	& \leq |(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+v^tv - 2v^t(M\gamma)|\\
% 	& \leq |(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+ v^tv| + 2|v^t(M\gamma)|\\
%	& \leq \left|(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+ v^tv\right| + 2 |\alpha_0| bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}} \sqrt{b_{\varepsilon}^*}.
%\end{align*}
%
%Now, following the steps of the Fincke-Pohst algorithm, we first generate the matrix $R$ via Cholesky decomposition applied to $B^{\text{T}}B$. In particular, this means that we don't need to know $B$ explicitly, but rather $B^TB$, where
%\[B^TB = (M\Gamma_{\tau})^T(M\Gamma_{\tau}) = \Gamma_{\tau}^T(M^TM)\Gamma_{\tau}\]
%where both $M^TM$ and $\Gamma_{\tau}$ are integral matrices. 
%
%
%\subsection{Non-Archimedean sieve}
%%Let $v\in T$. To simplify our exposition, we slightly abuse notation and we write $v=\ord_p:\bar{\QQ}_p\to\QQ$. We take $l,h\in\RR^{S^*}$ with $0\leq l\leq h$ and $l_v/\log p\geq \max\bigl(\tfrac{1}{p-1},v(\mu_0)\bigl)-v(\lambda_0)$, and then we consider the 
%%translated lattice $\Gamma_v\subset \ZZ^\unit$ defined below.  We say that $(x,y)\in\Sigma$ with $m\in\ZZ^{\unit}$ is determined by some $\gamma\in \Gamma_v$ if the entries of $\gamma$ are a (fixed) permutation of the entries of $m$. Let $\mathcal E_v\subseteq \RR^\unit$ be the ellipsoid constructed in \eqref{def:ellnonarch}.
%%\begin{lemma}\label{lem:nonarchsieve}
%%Any $(x,y)\in\Sigma_v(l,h)$ is determined by some $\gamma\in \Gamma_v\cap\mathcal E_v.$
%%\end{lemma}
%%
%%In the remaining of this section we prove this lemma.
%
%---------------------------------------------------------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------------------------------------------------------%

%---------------------------------------------------------------------------------------------------------------------------------------------%

\section{The non-Archimedean Sieve}
\label{sec:nonArchSieve}

Let $v \in \{1, \dots, \nu\}$. We take vectors $\mathbf{l},\mathbf{h} \in \mathbb{R}^{\nu+r}$ with $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ and 
\[\frac{l_v}{\log(p)} \geq \max\left( \frac{1}{p-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2)\]
and then consider the translated lattice $\Gamma_v \subseteq \mathbb{Z}^{\nu + r}$ defined below. We say that ${\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}}$ is determined by some $\mathbf{y} \in \Gamma_v$ if the entries of $\mathbf{y}$ are a (fixed) permutation of the entries of $\mathbf{m}$. Let $\mathcal{E}_v$ be the ellipsoid constructed in \eqref{def:ellp}. 

\begin{lemma} \label{lem:mainnonarch}
Any $(\tilde{x},\tilde{y}) \in \Sigma_v(l,h)$ is determined by some $\mathbf{y} \in \Gamma_v \cap \mathcal{E}_v$. 
\end{lemma}

In the remainder of this section, we prove this lemma. 

We begin by applying the results of \autoref{sec:SmallBoundForSpecialCase}. In particular, we consider the form
\[\Lambda_v = \sum_{i = 1}^{1+\nu+r} b_i\alpha_i\]
where
\[b_1 = 1, \quad b_{1+i} = n_i \ \text{ for } i \in \{1, \dots, \nu\},\]
\[ b_{1 + \nu+i} = a_i \ \text{ for } i \in \{1, \dots, r\},\]
and
\[\alpha_1 = \log_{p_l} \delta_1, \quad \alpha_{1+i} = \log_{p_l}\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(l)}}\right)  \ \text{ for } i \in \{1, \dots, \nu\},\]
\[\alpha_{1+ \nu+i} = \log_{p_l}\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(l)}}\right)
\ \text{ for } i \in \{1, \dots, r\}.\]

We apply Lemma~\ref{lem:Delta1} by which $\sum_{j = 1}^{\nu} n_ja_{vj}$ can be computed directly provided ${\ord_{p_v}(\delta_1) \neq 0}$. In doing so, we assume for the remainder of this chapter that $\ord_{p_v}(\delta_1) = 0$. Furthermore, we apply Lemma~\ref{Lem:specialcase} to obtain a small bound on $\sum_{j = 1}^{\nu} n_ja_{vj}$ when $\ord_{p_v}(\alpha_1) < \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_v}(\alpha_i)$. Again, in doing so, we assume 
\[\ord_{p_v}(\alpha_1) \geq \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_v}(\alpha_i)\]
for the remainder of this chapter. 

We now set some notation and give some preliminaries for the $p_l$-adic reduction procedures. Let $I$ be the set of all indices $i' \in \{2, \dots, 1+ \nu + r\}$ for which
\[\ord_{p_v}(\alpha_{i'}) = \min_{2\leq i\leq 1+ \nu+ r} \ord_{p_v}(\alpha_i).\]
Following \cite{Ham}, we are always in the case where there exists an index $i' \in I$ such that $\alpha_i/\alpha_{i'} \in \mathbb{Q}_{p_l}$ for $i = 1, \dots, 1+ \nu+ r$. Thus, let $\hat{i}$ denote this index. We define
\[\beta_i = - \frac{\alpha_i}{\alpha_{\hat{i}}} \quad i = 1, \dots, 1+ \nu+ r,\]
and 
\[\Lambda'_v = \frac{1}{\alpha_{\hat{i}}}\Lambda_v = \sum_{i = 1}^{1+ \nu+ r} b_i(-\beta_i).\]
Now, we have $\beta_i \in \mathbb{Z}_{p_v}$ for $i = 1, \dots, 1+ \nu+ r$. 

\begin{lemma} \label{Lem:19.1}
Suppose $\ord_{p_v}(\delta_1) = 0$ and 
\[\sum_{i = 1}^v n_{i}a_{li} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2).\]
Then
\[\ord_{p_v}(\Lambda_v') = \sum_{i = 1}^v n_{i}a_{li} + \ord_{p_l}(\delta_2) - \ord_{p_l}(\alpha_{\hat{i}}).\]
\end{lemma}

\begin{proof}
Immediate from Lemma \ref{lem:DiscG} and Lemma \ref{lem:Lambda}. 
\end{proof}

We now describe the $p_v$-adic reduction procedure. Recall that $l_v$ is a constant such that
\[\frac{l_v}{\log(p)} \geq \max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2).\]
Now, let $\mu$ be the largest element of $\mathbb{Z}_{\geq 0}$ at most
\[\mu \leq \frac{l_v}{\log(p)} - \ord_{p_l}(\alpha_{\hat{i}}) + \ord_{p_l}(\delta_2).\]

For each $x \in \mathbb{Z}_{p_l}$, let $x^{\{\mu\}}$ denote the unique rational integer in $[0,p_l^{\mu} - 1]$ such that $\ord_{p_l}(x - x^{\mu}) \geq \mu$ (ie. $x \equiv x^{\{\mu\}} \pmod{p_l^{\mu}}$). 

Let $\Gamma_{v}$ be the $(\nu+r)$-dimensional translated lattice determined by $A_{v}\mathbf{x} + \mathbf{w}$, where $A_{v}$ is the diagonal matrix having $\hat{i}^{\text{th}}$ row 
\[\left(\beta_2^{\{\mu\}}, \cdots, \beta_{\hat{i} - 1}^{\{\mu\}}, p_l^{\mu}, \beta_{\hat{i} + 1}^{\{\mu\}}, \cdots, \beta_{1+ \nu+ r}^{\{\mu\}}\right) \in \mathbb{Z}^{\nu+r}.\]
Here, $p_l^{\mu}$ is the $(\hat{i},\hat{i})$ entry of $A_{v}$. That is, 
\[A_{v} = 
\begin{pmatrix}
1	& 		&		&		&		&		&	\\
	& \ddots	& 		&		& 0		& 		&	\\
	&		& 1		&		&		&		&	\\
	\beta_2^{\{\mu\}}& \cdots & \beta_{\hat{i} - 1}^{\{\mu\}} & p_l^{\mu} & \beta_{\hat{i} + 1}^{\{\mu\}}& \cdots &\beta_{1+ \nu+ r}^{\{\mu\}}\\
	& 		& 		& 		& 1		&		&	\\	
	& 0		& 		& 		&		& \ddots	&	\\	
	& 		& 		& 		&		& 		& 1	\\	
\end{pmatrix}.\]
Additionally, $\mathbf{w}$ is the vector whose only non-zero entry is the $\hat{i}^{\text{th}}$ element, $ \beta_1^{\{\mu\}}$,
\[\mathbf{w} = (0, \dots 0, \beta_1^{\{\mu\}},0, \dots, 0)^T \in \mathbb{Z}^{\nu + r}.\]

Of course, we must compute the $\beta_i$ to $p_l$-adic precision at least $\mu$ in order to avoid errors here. 
Let $\mathbf{y} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{\nu + r}$ denote a solution to \eqref{eq:EfficientSunit}. 

\begin{lemma}
Suppose $\ord_{p_v}(\delta_1) = 0$ and 
\[\sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2).\]
Then the following equivalence holds: 
\begin{align*}
\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}) 
	& \quad \text{ if and only if } \quad \ord_{p_v}(\Lambda_v') \geq \mu \\
	& \quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v.
\end{align*}
\end{lemma} 

\begin{proof}
By Lemma \ref{Lem:19.1}, the assumption means that 
\[\ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}}).\]

Now, suppose 
\[\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
We thus have
\begin{align*}
\ord_{p_v}(\Lambda_v')	
	& = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}})\\
	& \geq  \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}})\\	
	& = \mu.
\end{align*}
Conversely, suppose $\ord_{p_v}(\Lambda_v') \geq \mu$. Then
\[\mu \leq \ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}}).\]
That is, 
\[\sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
Hence, it follows that $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})$ if and only if $\ord_{p_v}(\Lambda_v') \geq \mu$.

Now, suppose $\mathbf{y}= (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{\nu + r}$ is a solution to \eqref{eq:EfficientSunit}. Suppose further that $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})$ so that $\ord_{p_v}(\Lambda_v') \geq \mu$. Let
\[\lambda = \frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\]
and consider the $(\nu + r)$-dimensional vector
\[\mathbf{x}= (n_1, \dots, n_{\hat{i} -1}, \lambda, n_{\hat{i} +1}, \dots, n_{\nu}, a_1, \dots, a_r).\]
We claim $\mathbf{x} \in \mathbb{Z}^{\nu + r}$. That is, $\lambda \in \mathbb{Z}$, meaning that $\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})$ is divisible by $p_v^{\mu}$, or equivalently, 
\[\ord_{p_v}\left(\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu.\]
Indeed, since 
\[\ord_{p_{v}}\left(\beta_{i}^{\{\mu\}}-\beta_{i}\right) \geq \mu \quad \text { for } i=1, \dots, 1+\nu+r,\]
by definition, it follows that $\beta_{i}^{\{\mu\}}$ and $\beta_{i}$ share the first $\mu - 1$ terms and thus $\ord_{p_v}(\beta_i) = \ord_{p_v}(\beta_i^{\{\mu\}})$.
Now, to compute this order, we only need to concern ourselves with the first non-zero term in the series expansion of $\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})$. Since $\beta_{i}^{\{\mu\}}$ and $\beta_{i}$ share the first $\mu - 1$ terms, it follows that showing
\[\ord_{p_v}\left(\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu\]
is equivalent to showing that 
\[\ord_{p_l}(\Lambda_l') \geq \mu.\]
Of course, this latter inequality is true by assumption. Thus $\lambda \in \mathbb{Z}$. 

Then, computing $A_{v}\mathbf{x} + \mathbf{w}$ yields
\begin{align*}
 A_{v}\mathbf{x} + \mathbf{w} &
& = \begin{pmatrix}
b_2 \\ \vdots \\ b_{\hat{i} -1} \\ 
 b^* \\
b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1} \\
\end{pmatrix},
\end{align*}
where 
\[b^* =b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} + \lambda p_l^{\mu} + b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots + b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}} + \beta_1^{\{\mu\}}.\]
Now, 
\[ \lambda p_v^{\mu} = p_v^{\mu}\frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}) = \sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}),\]
hence
\begin{align*}
& b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} + b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots + b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}} + \lambda p_l^{\mu} + \beta_1^{\{\mu\}}\\
& = b_{\hat{i}}(-\beta_{\hat{i}}^{\{\mu\}})\\
& = b_{\hat{i}}
\end{align*}
where the last equality follows from the fact that 
\[-\beta_i = \frac{\alpha_{\hat{i}}}{\alpha_{\hat{i}}} =1.\]
Thus, 
\[A_{v}\mathbf{x} + \mathbf{w} = \begin{pmatrix}
b_2 \\ \vdots \\ b_{\hat{i} -1} \\ b_{\hat{i}} \\ b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1}
\end{pmatrix} = 
\begin{pmatrix}
n_1 \\ \vdots \\ n_{\nu} \\ a_1 \\ \vdots \\ a_r \end{pmatrix} = \mathbf{y}.\]
and $\mathbf{y} \in \Gamma_v$. 

%Our assumption gives $n_p-a_p\geq \max(0,\ord_p(\mu_0))-\ord_p(\lambda_0)$ and then Lemma~\ref{lem:padiccomp} implies that $\ord_p(\mu_0)=0$. Therefore, on using again our assumption which assures that $n_p-a_p> \tfrac{1}{p-1}-\ord_p(\lambda_0)$, we see that an application of Lemma~\ref{lem:padiccomp}  gives  $$(n_p-a_p)+\ord_p(\lambda_0)=\ord_p(\Lambda_p)=\ord_p(\Lambda'_p)+\ord_p(\xi_p).$$
%Thus $n_p-a_p\geq l_v'-\ord_p(\xi_p/\lambda_0)$ if and only if $\ord_p(\Lambda'_p)\geq l_v'$. Further, the TdW arguments show that $\ord_p(\Lambda'_p)\geq l_v'$ if and only if $m'\in\Gamma_v$. On combining we deduce the lemma.
\end{proof}


%
%
%
%
%
%
%
%
%
%
%
%Put
%\[Q = \sum_{i = 2}^{v+2} W_i^2 B_i^2.\]
%
%\begin{lem} \label{lem:LLL}
%If $\ell(\Gamma_{\mu},\mathbf{y}) > Q^{1/2}$ then
%\[\sum_{i = 1}^v n_{i}a_{li} \leq \max\left\{ \frac{1}{p_l-1} - \ord_{p_l}(\delta_2), \mu - d_l - 1,0\right\}\]
%\end{lem}
%
%\begin{proof}
%We prove the contrapositive. Assume 
%\[\sum_{i = 1}^v n_{i}a_{li} > \frac{1}{p_l-1} - \ord_{p_l}(\delta_2), \quad \sum_{i = 1}^v n_{i}a_{li} > \mu - d_l 
%\quad \text{ and } \quad \sum_{i = 1}^v n_{i}a_{li} > 0.\]
%Consider the vector
%\[\mathbf{x} = A_{\mu}
%\begin{pmatrix}
%b_2\\
%\vdots\\
%b_{\hat{i}-1}\\
%b_{\hat{i}+1}\\
%\vdots\\
%b_{v+2}\\
%\lambda
%\end{pmatrix}
%= 
%\begin{pmatrix}
%W_2b_2\\
%\vdots\\
%W_{\hat{i}-1}b_{\hat{i}-1}\\
%W_{\hat{i}+1}b_{\hat{i}+1}\\
%\vdots\\
%W_{v+2}b_{v+2}\\
%-W_{\hat{i}}b_{\hat{i}}
%\end{pmatrix}
%+ \mathbf{y}.\]
%By Lemma~\ref{Lem:19.1},  
%\[\ord_{p_l}\left( \sum_{i=1}^{v+2}b_i(-\beta_i)\right) = \ord_{p_l}(\Lambda_l') \geq\sum_{i = 1}^v n_{i}a_{li} + d_l \geq \mu.\]
%Since $\ord_{p_l}(\beta_i^{\{\mu\}} - \beta_i) \geq \mu$ for $i = 1, \dots, v+2$, it follows that
%\[\ord_{p_l}\left( \sum_{i=1}^{v+2}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu,\]
%so that $\lambda \in \mathbb{Z}$. Hence $\mathbf{x} \in \Gamma_{\mu}$. Now $\sum_{i = 1}^v n_{i}a_{li} > 0$ so that there exists some $i$ such that $n_ia_{li} \neq 0$, and in particular, $b_{1+i} = n_i \neq 0$. Thus we cannot have $\mathbf{x} = \mathbf{y}$. Therefore, 
%\[\ell(\Gamma_{\mu}, \mathbf{y})^2 \leq |\mathbf{x} - \mathbf{y}|^2 = \sum_{i = 2}^{v+2}W_i^2 b_i^2
%\leq  \sum_{i = 2}^{v+2}W_i^2 |b_i|^2 \leq  \sum_{i = 2}^{v+2}W_i^2 B_i^2 = Q.\]
%\end{proof}

%The reduction procedure works as follows. Taking $A_{\mu}$ as input, we first compute an LLL-reduced basis for $\Gamma_{\mu}$. Then, we find a lower bound for $\ell(\Gamma_{\mu}, \mathbf{y})$. If the lower bound is not greater than $Q^{1/2}$ so that Lemma \ref{lem:LLL} does not give a new upper bound, we increase $\mu$ and try the procedure again. If we find that several increases of $\mu$ have failed to yield a new upper bound $N_l$ and that the value of $\mu$ has become significantly larger than it was initially, we move onto the next $l \in \{1, \dots, v\}$.
%
%If the lower bound is greater than $Q^{1/2}$, Lemma \ref{lem:LLL} gives a new upper bound $N_l$ for $\sum_{i = 1}^v n_{i}a_{li}$ and hence for $m$
%\[m = \frac{\sum_{j = 1}^{v}n_ja_{lj} + r_l + t_l}{\alpha_l} < \frac{N_l+ r_l + t_l}{\alpha_l} = M.\]
%If $M < 3000$, we exit the algorithm and enter the brute force search. Otherwise, we update the bounds $N_1, \dots, N_{l-1}, N_{l+1}, \dots, N_v$ via
%\[\sum_{j=1}^v n_ja_{ij} = m\alpha_i - r_i - t_i \leq M\alpha_i - r_i - t_i = N_i.\]
%Then using 
%\[|n_l| \leq \max_{1 \leq i \leq v}|n_i| \leq ||A^{-1}||_{\infty}\max_{1 \leq i\leq v}\sum_{j = 1}^v n_j a_{ij}
%\leq ||A^{-1}||_{\infty} \max_{1 \leq i\leq v}(N_i) = B_{l+1}.\]
%we update the $B_i$ and repeat the above procedure until $M < 3000$ or until no further improvement can be made on the $B_i$, in which case we move onto the next $l \in \{1, \dots, v\}$.

Define 
\[c_{p_v}=\log p_v\left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right).\]

\begin{corollary} \label{lem:cpequiv}
Assume that $h_{p_v}(z)>\max(0,c_{p_v})$. Then the following equivalence holds: 
\[h_{p_v}(z)\geq \log{p_v}\left(\mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})\right) \quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v.\]
\end{corollary}
\begin{proof}
Recall from Proposition~\ref{prop:heightdecomp} that 
\[h_{p_v}(z) = 
\begin{cases}
\log(p_v)|u_v - r_v| \\
0
\end{cases}.\]
Since $h_{p_v}(z) > 0$, it follows that $h_{p_v}(z) = \log(p_v)|u_v - r_v|$. Hence the assumption becomes
\[\log(p_v)|u_v - r_v| = h_{p_v}(z) > \log p_v\left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right),\]
or equivalently, 
\[\sum_{j = 1}^{\nu}n_ja_{vj} > \left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right).\]
Moreover, the conclusion is equivalent to 
\[\log(p_v)|u_v - r_v| \geq \log{p_v}\left(\mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})\right) 
	\quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v,\]
or, 
\[\sum_{j = 1}^{\nu}n_ja_{vj} \geq \left(\mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})\right) 
	\quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v,\]
which is the previous lemma. 

%This follows from the above lemma, since Proposition~\ref{prop:heightdecomp} together with $h_p(z)>0$ implies that $h_p(z)=\log p(n_p-a_p)$.
\end{proof}

We now prove Lemma~\ref{lem:mainnonarch}. 

\begin{proof}[Proof of Lemma~\ref{lem:mainnonarch}]
If $(n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r+\nu}$ is a solution of \eqref{eq:EfficientSunit}, then, by definition, it corresponds to a solution $(\tilde{x},\tilde{y}) \in \Sigma_v(\mathbf{l},\mathbf{h})$. 
Hence $h_v(z)>l_v$, where $l_v$ is a constant such that
\[\frac{l_v}{\log(p_v)} \geq \max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2).\]
That is, 
\[h_v(z) > l_v \geq \log(p_v)\left(\max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2)\right) = c_p.\]
Now, recall that $\mathbf{l} \geq \mathbf{0}$ so that $l_v \geq 0$. It thus follows that 
\[h_v(z) > l_v \geq
\begin{cases}
0\\
c_p
\end{cases}
\implies h_v(z) >\max(0,c_p).\]
In other words, the conditions of Corollary~\ref{lem:cpequiv} are satisfied. 

Now, recall that $\mu$ is the largest element of $\mathbb{Z}_{\geq 0}$ at most
\[\mu \leq \frac{l_v}{\log(p_v)} - \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2).\]
That is
\[\frac{l_v}{\log(p_v)} \geq \mu + \ord_{p_v}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\]
so that
\[h_v(z) > l_v \geq \log(p_v)\left(\mu + \ord_{p_l}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\right).\]
Now, by Corollary~\ref{lem:cpequiv}, we must have $\mathbf{y} \in \Gamma_v$. This shows that $(\tilde{x},\tilde{y})$ is determined by $\mathbf{y}=\mathbf{m}'\in\Gamma_v$, which proves Lemma~\ref{lem:mainnonarch}.
%
%If $h_v(z)>l_v$ then $h_v(z)>\max(0,c_p)$ since $l\geq 0$ and $l_v\geq c_p$ by assumption. Further, it holds that $l_v/\log p\geq l_v'-v(\xi_p/\lambda_0)$ by the definition of $l_v'$. Hence $h_v(z)\geq \log p(l_v'-v(\xi_p/\lambda_0))$ and then the above corollary implies that $m'\in\Gamma_v$. This shows that $(x,y)$ is determined by $\gamma=m'\in\Gamma_v$, which proves Lemma~\ref{lem:nonarchsieve}.
\end{proof}

Finally, suppose that $\mathbf{y}\in \Gamma_v\cap \mathcal E_v$. Let $M=M_v$ be the matrix defining the ellipsoid $\mathcal{E}_v$. That is
\begin{align*}
M &=\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
	DA & 0 & \dots & 0 & 0\\
	0 & \sqrt{\frac{b}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
	0 & 0  & \sqrt{\frac{b}{b_{\varepsilon 2}}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\ 
	0 & 0 & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon}}} \\
	\end{pmatrix}.
\end{align*}	
Recall that $A_{v}\mathbf{x} + \mathbf{w}$ defines the lattice $\Gamma_v$. In particular, since $\mathbf{y}\in \Gamma_v\cap \mathcal E_v$, there exists $\mathbf{x}\in \mathbb{R}^{r + \nu}$ such that $\mathbf{y}=A_v \mathbf{x}+\mathbf{w}$ and ${\mathbf{y}^TM^TM\mathbf{y}\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})}$. We thus have
\[(A_v \mathbf{x}+\mathbf{w})^TM^TM(A_v \mathbf{x}+\mathbf{w}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
As $A_{v}$ is clearly invertible, with matrix inverse
\[A_{v}^{-1} = \begin{pmatrix}
1	& 		&		&		&		&		&	\\
	& \ddots	& 		&		& 0		& 		&	\\
	&		& 1		&		&		&		&	\\
	-\frac{\beta_2^{\{\mu\}}}{p_l^{\mu}} & \cdots & -\frac{\beta_{\hat{i} - 1}^{\{\mu\}}}{p_l^{\mu}} & \frac{1}{p_l^{\mu}} & -\frac{\beta_{\hat{i} + 1}^{\{\mu\}}}{p_l^{\mu}}& \cdots &-\frac{\beta_{1+ \nu+ r}^{\{\mu\}}}{p_l^{\mu}}\\
	& 		& 		& 		& 1		&		&	\\	
	& 0		& 		& 		&		& \ddots	&	\\	
	& 		& 		& 		&		& 		& 1	\\
	\end{pmatrix},\]
we can find a vector $\mathbf{c}$ such that $A_{v}\mathbf{c} = -\mathbf{w}$. Indeed, this vector is $\mathbf{c} = A_{v}^{-1}(-\mathbf{w})$, where
\[\mathbf{c}=\begin{pmatrix}
	0 \\ \vdots \\ 0 \\-\frac{\beta_1^{\{\mu\}}}{p^{\{\mu\}}} \\ 0 \\ \vdots \\ 0
\end{pmatrix}.\]
Now, 
\begin{align*}
(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
	& \geq (A_v \mathbf{x}+\mathbf{w})^TM^TM(A_v \mathbf{x}+\mathbf{w}) \\
	& = (A_v \mathbf{x}-A_v\mathbf{c})^TM^TM(A_v \mathbf{x}-A_v\mathbf{c})\\
	& = (\mathbf{x}-\mathbf{c})^T(MA_v)^TMA_v(\mathbf{x}-\mathbf{c})\\
	& = (\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c})
\end{align*}
where $B = MA_v$. That is, we are left to solve
\[(\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
As in \autoref{sec:archsieve} finding all vectors satisfying this inequality amounts to computing all solutions to \eqref{eq:EfficientSunit} contained in $\Sigma_{v}(\mathbf{l}, \mathbf{h})$. The set of vectors $\mathbf{x}$ can be found using the Fincke-Pohst algorithm outlined in \autoref{subsec:FinckePohst}. 
 
%---------------------------------------------------------------------------------------------------------------------------------------------%

\endinput

Any text after an \endinput is ignored.
You could put scraps here or things in progress.
